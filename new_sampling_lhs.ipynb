{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vamsi-Malineni/Research-work/blob/master/new_sampling_lhs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YnWZBDgfher"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import time\n",
        "import pandas as pd\n",
        "import math\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfK8bOOAgOtM"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "\n",
        "class pinn:\n",
        "    # Initialize the class\n",
        "    def __init__(self, data_idx, data_t0, data_sup_b_train, layers, N_train, batch_size,load = False, file=None):\n",
        "        \n",
        "#============================================================================================================================#\n",
        "#=============================================Loading data ==================================================================#\n",
        "#============================================================================================================================#\n",
        "        self.data_t0 = data_t0\n",
        "        self.data_sup_b_train = data_sup_b_train\n",
        "        self.data_idx = data_idx\n",
        "        self.N_train = N_train\n",
        "        self.batch_size=batch_size\n",
        "\n",
        "        self.lowb = data_idx.min(0)  \n",
        "        self.upb = data_idx.max(0)\n",
        "\n",
        "        self.layers = layers\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=======================================Loading / Initializing NN============================================================#\n",
        "#============================================================================================================================#\n",
        "        if load==True:\n",
        "            # collecting weights and biases from the pickle file\n",
        "            self.weights,self.biases=self.load_parameters(file,self.layers)\n",
        "            \n",
        "\n",
        "        if load ==False:\n",
        "            # Initializing weights and biases for model using xavier initialization method.\n",
        "            self.weights, self.biases = self.initialize_NN(layers)\n",
        "\n",
        "            # Adaptive weighting constants initialized to 1.\n",
        "#             self.beta=0.9\n",
        "#             self.adaptive_constant_bcs_val=np.array(1.0)  # arw for boundary conditions\n",
        "#             self.adaptive_constant_ics_val=np.array(1.0)  # arw for initial conditions\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Specifying Placeholders========================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "\n",
        "        # learning rate placeholder\n",
        "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "        \n",
        "        # initial condition placeholders\n",
        "        self.x_ini_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.y_ini_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_ini_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u_ini_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.v_ini_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "        # boundary condition placeholders\n",
        "        self.x_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.y_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.t_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.U_bc1_tf = tf.placeholder(tf.float32, shape=(None, 2))\n",
        "\n",
        "        self.x_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.y_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.t_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.U_bc2_tf = tf.placeholder(tf.float32, shape=(None, 2))\n",
        "\n",
        "        self.x_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.y_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.t_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.U_bc3_tf = tf.placeholder(tf.float32, shape=(None, 2))\n",
        "\n",
        "        self.x_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.y_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.t_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.U_bc4_tf = tf.placeholder(tf.float32, shape=(None, 2))\n",
        "\n",
        "        # domain residual placeholders\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.y_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "        # defining a placeholder for adaptive constant\n",
        "#         self.adaptive_constant_bcs_tf=tf.placeholder(tf.float32,shape=self.adaptive_constant_bcs_val.shape)\n",
        "#         self.adaptive_constant_ics_tf=tf.placeholder(tf.float32,shape=self.adaptive_constant_ics_val.shape)\n",
        "        \n",
        "#============================================================================================================================#\n",
        "#=============================================Evaluating Predictions=========================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        # Initial value predictions\n",
        "        self.u_ini_pred, self.v_ini_pred, self.p_ini_pred = self.net_NS(self.x_ini_tf, self.y_ini_tf, self.t_ini_tf)\n",
        "        \n",
        "        # Boundary value predictions\n",
        "\n",
        "        self.u_bc1_pred, self.v_bc1_pred,_,_,_,_= self.net_f_NS(self.x_bc1_tf, self.y_bc1_tf,self.t_bc1_tf)\n",
        "        self.u_bc2_pred, self.v_bc2_pred,_,_,_,_= self.net_f_NS(self.x_bc2_tf, self.y_bc2_tf,self.t_bc2_tf)\n",
        "        self.u_bc3_pred, self.v_bc3_pred,_,_,_,_= self.net_f_NS(self.x_bc3_tf, self.y_bc3_tf,self.t_bc3_tf)\n",
        "        self.u_bc4_pred, self.v_bc4_pred,_,_,_,_= self.net_f_NS(self.x_bc4_tf, self.y_bc4_tf,self.t_bc4_tf)\n",
        "        \n",
        "        self.U_bc1_pred = tf.concat([self.u_bc1_pred, self.v_bc1_pred], axis=1)\n",
        "        self.U_bc2_pred = tf.concat([self.u_bc2_pred, self.v_bc2_pred], axis=1)\n",
        "        self.U_bc3_pred = tf.concat([self.u_bc3_pred, self.v_bc3_pred], axis=1)\n",
        "        self.U_bc4_pred = tf.concat([self.u_bc4_pred, self.v_bc4_pred], axis=1)\n",
        "\n",
        "        self.u_pred, self.v_pred, self.p_pred, self.f_u_pred, self.f_v_pred, self.f_e_pred = \\\n",
        "            self.net_f_NS(self.x_tf, self.y_tf, self.t_tf)\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Defining loss fn===============================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        self.loss_bcs=(tf.reduce_mean(tf.square(self.U_bc1_pred - self.U_bc1_tf)+tf.square(self.U_bc2_pred - self.U_bc2_tf)+tf.square(self.U_bc3_pred - self.U_bc3_tf)+tf.square(self.U_bc4_pred - self.U_bc4_tf)))\n",
        "        self.loss_ics=(tf.reduce_mean(tf.square(self.u_ini_tf - self.u_ini_pred)) + tf.reduce_mean(tf.square(self.v_ini_tf - self.v_ini_pred)))        \n",
        "\n",
        "        # Defining loss function for residual in the domain \n",
        "        \n",
        "        self.loss_res= tf.reduce_mean(tf.square(self.f_u_pred)) + tf.reduce_mean(tf.square(self.f_v_pred)) + tf.reduce_mean(tf.square(self.f_e_pred))\n",
        "\n",
        "\n",
        "        # set loss function\n",
        "        self.loss =self.loss_res + self.loss_bcs + self.loss_ics\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Setting up optimizer===========================================================#\n",
        "#============================================================================================================================#\n",
        "        self.global_step=tf.Variable(0,trainable=False)\n",
        "        starter_learning_rate=1e-3\n",
        "        self.learning_rate=tf.train.exponential_decay(starter_learning_rate,self.global_step,1000,0.9,staircase=False)\n",
        "\n",
        "        # set optimizer\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\n",
        "                                                                method='L-BFGS-B',\n",
        "                                                                options={'maxiter': 50000,\n",
        "                                                                         'maxfun': 50000,\n",
        "                                                                         'maxcor': 50,\n",
        "                                                                         'maxls': 50,\n",
        "                                                                         'ftol': 1.0 * np.finfo(float).eps})\n",
        "\n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer(self.learning_rate)\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss,global_step=self.global_step)\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Adaptive weighting constants===================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        # Collecting gradients of the individual loss terms wrt the parameters of the network\n",
        "#         self.grad_res=[]\n",
        "#         self.grad_bcs=[]\n",
        "#         self.grad_ics=[]\n",
        "        \n",
        "#         for i in range(len(self.layers)-1):\n",
        "#           self.grad_res.append(tf.gradients(self.loss_res,self.weights[i])[0])\n",
        "#           self.grad_bcs.append(tf.gradients(self.loss_bcs,self.weights[i])[0])\n",
        "#           self.grad_ics.append(tf.gradients(self.loss_ics,self.weights[i])[0])\n",
        "        \n",
        "#         # Collecting the adaptive constants for initial and boundary conditions\n",
        "#         self.adaptive_constant_bcs_list=[]\n",
        "#         self.adaptive_constant_ics_list=[]\n",
        "\n",
        "#         self.adaptive_constant_bcs_log=[]\n",
        "#         self.adaptive_constant_ics_log=[]\n",
        "\n",
        "#         for i in range(len(self.layers)-1):\n",
        "#           self.adaptive_constant_bcs_list.append(\n",
        "#               tf.reduce_max(tf.abs(self.grad_res[i])) / tf.reduce_mean(tf.abs(self.grad_bcs[i]))\n",
        "#           )\n",
        "#           self.adaptive_constant_ics_list.append(\n",
        "#               tf.reduce_max(tf.abs(self.grad_res[i])) / tf.reduce_mean(tf.abs(self.grad_ics[i]))\n",
        "#           )\n",
        "        \n",
        "#         self.adaptive_constant_bcs=tf.reduce_max(tf.stack(self.adaptive_constant_bcs_list))\n",
        "#         self.adpative_constant_ics=tf.reduce_max(tf.stack(self.adaptive_constant_ics_list))\n",
        "        \n",
        "#============================================================================================================================#\n",
        "#=============================================initializing session===========================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        # Initializing Tensorflow variables\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Logging loss components========================================================#\n",
        "#============================================================================================================================#\n",
        "        self.loss_res_log = []\n",
        "        self.loss_bcs_log = []\n",
        "        self.loss_ics_log = []\n",
        "#============================================================================================================================#\n",
        "#=============================================Data in batches================================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "        # Creating batches for domain data\n",
        "    def summon_batch_domain(self,batch_size,start):\n",
        "      ''' \n",
        "      This function returns a list containing randomnly picked points from the domain\n",
        "      '''\n",
        "      data=copy.deepcopy(self.data_idx)\n",
        "      points=[]\n",
        "\n",
        "      for i in range(start,len(data),batch_size): # Something is wrong here\n",
        "\n",
        "        points.append(data[i:i+batch_size,0:3])\n",
        "        break # breaks after the first iteration\n",
        "\n",
        "      return points\n",
        "\n",
        "    def domain_batches(self,batch_size):\n",
        "      '''\n",
        "      This function is used to call the domain data points in batches\n",
        "      This function returns an array of arrays of shape(438,1) each of the 438 arrays\n",
        "      will have batch size number of points\n",
        "      '''\n",
        "      batches=[]\n",
        "      num_batches=math.ceil(self.N_train/batch_size)\n",
        "\n",
        "      for i in range(0,len(data_idx),batch_size):\n",
        "        batches.append(self.summon_batch_domain(batch_size,i))\n",
        "\n",
        "      return np.asarray(batches,dtype=object) \n",
        "\n",
        "# Creating batches for initial conditions\n",
        "    def summon_batch_ic(self,batch_size,start):\n",
        "\n",
        "      data=copy.deepcopy(data_t0)\n",
        "      points=[]\n",
        "\n",
        "      for i in range(start,len(data),batch_size): \n",
        "\n",
        "        points.append(data[i:i+batch_size])\n",
        "        break # breaks after the first iteration\n",
        "\n",
        "      return points\n",
        "    def ic_batches(self,batch_size):\n",
        "      batches=[]\n",
        "      num_batches=math.ceil(self.data_t0.shape[0]/batch_size)\n",
        "\n",
        "      for i in range(0,len(self.data_t0),batch_size):\n",
        "        batches.append(self.summon_batch_ic(batch_size,i))\n",
        "      return batches\n",
        "      #return np.asarray(batches,dtype=object)       \n",
        "\n",
        "# Creatng batches for boundary condition\n",
        "    def summon_batch_bc(self,batch_size,bc_con,start):\n",
        "      \n",
        "      if bc_con==1:\n",
        "        data=copy.deepcopy(data_sup_b_train[0:20000,:])\n",
        "      elif bc_con==2:\n",
        "        data=copy.deepcopy(data_sup_b_train[20000:40000,:])\n",
        "      elif bc_con==3:\n",
        "        data=copy.deepcopy(data_sup_b_train[40000:60000,:])\n",
        "      elif bc_con==4:\n",
        "        data=copy.deepcopy(data_sup_b_train[60000:80000,:])\n",
        "\n",
        "      points=[]\n",
        "\n",
        "      for i in range(start,len(data),batch_size): \n",
        "\n",
        "        points.append(data[i:i+batch_size])\n",
        "        break # breaks after the first iteration\n",
        "\n",
        "      return points\t\n",
        "    \n",
        "    def bc_batches(self,batch_size,bc_con):\n",
        "\n",
        "      batches=[]\n",
        "      \n",
        "      for i in range(0,int(len(data_sup_b_train)/4),batch_size):\n",
        "        batches.append(self.summon_batch_bc(batch_size,bc_con,i))\n",
        "      return batches\n",
        "      #return np.asarray(batches,dtype=object) \n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Utility fns= ==================================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "# initialize the weights and biases\n",
        "    def initialize_NN(self, layers):\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "# xavier used to initialize the weight\n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "\n",
        "# saving the weights and biases for transfer learning\n",
        "    def save_parameters(self,fileDr):\n",
        "        weights=self.sess.run(self.weights)\n",
        "        biases= self.sess.run(self.biases)\n",
        "        \n",
        "#         ac_bc=(self.adaptive_constant_bcs_val)\n",
        "#         ac_ic=(self.adaptive_constant_ics_val)\n",
        "                \n",
        "        root_path=Path(\"D:\\Vamsi\\Python scripts\")\n",
        "        my_path=root_path/fileDr\n",
        "        \n",
        "        with open(my_path,'wb') as f:\n",
        "            #pickle.dump([weights,biases,ac_bc,ac_ic],f)\n",
        "            pickle.dump([weights,biases],f)\n",
        "            print(\"Parameters are saved in pickle file\")\n",
        "\n",
        "    def load_parameters(self,fileDr,layers):\n",
        "        tf_weights=[]\n",
        "        tf_biases=[]\n",
        "        num_layers=len(layers)\n",
        "        \n",
        "        root_path=Path(\"D:\\Vamsi\\Python scripts\")\n",
        "        my_path=root_path/fileDr\n",
        "        \n",
        "        # returns the weights and biases of the network as np array\n",
        "        with open(my_path,'rb') as f:\n",
        "            weights,biases=pickle.load(f)\n",
        "            assert num_layers == (len(weights)+1)\n",
        "        \n",
        "        # returns the weights and biases of the network as tf.variable\n",
        "        for num in range(0,num_layers-1):\n",
        "            W=tf.Variable(weights[num])\n",
        "            b=tf.Variable(biases[num])\n",
        "            tf_weights.append(W)\n",
        "            tf_biases.append(b)\n",
        "         \n",
        "        \n",
        "        print(\"Parameters are loaded succesffuly\")\n",
        "        \n",
        "        return tf_weights,tf_biases\n",
        "    \n",
        "    \n",
        "#============================================================================================================================#\n",
        "#=============================================Neural_net setup===============================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "\n",
        "    def neural_net(self, X):\n",
        "        num_layers = len(self.weights) + 1\n",
        "\n",
        "        H = 2.0 * (X - self.lowb) / (self.upb - self.lowb) - 1.0\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = self.weights[l]\n",
        "            b = self.biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = self.weights[-1]\n",
        "        b = self.biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "\n",
        "    # supervised data driven\n",
        "    def net_NS(self, x, y, t):\n",
        "\n",
        "        \n",
        "        psi_p = self.neural_net(tf.concat([x, y, t], 1))\n",
        "        psi = psi_p[:, 0:1]\n",
        "        p   = psi_p[:, 1:2]\n",
        "        \n",
        "        u=tf.gradients(psi,y)[0]\n",
        "        v=(-1) * tf.gradients(psi,x)[0]\n",
        "\n",
        "        return u, v, p\n",
        "\n",
        "    # unsupervised NS residual\n",
        "    def net_f_NS(self, x, y, t):\n",
        "\n",
        "        psi_p = self.neural_net(tf.concat([x, y, t], 1))\n",
        "        psi = psi_p[:, 0:1]\n",
        "        p   = psi_p[:, 1:2]\n",
        "        \n",
        "        u=tf.gradients(psi,y)[0]\n",
        "        v=(-1) * tf.gradients(psi,x)[0]\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_y = tf.gradients(u, y)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        u_yy = tf.gradients(u_y, y)[0]\n",
        "\n",
        "        v_t = tf.gradients(v, t)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "        v_y = tf.gradients(v, y)[0]\n",
        "        v_xx = tf.gradients(v_x, x)[0]\n",
        "        v_yy = tf.gradients(v_y, y)[0]\n",
        "\n",
        "        p_x = tf.gradients(p, x)[0]\n",
        "        p_y = tf.gradients(p, y)[0]\n",
        "\n",
        "        f_u = u_t + (u * u_x + v * u_y) + p_x - 0.01 * (u_xx + u_yy)\n",
        "        f_v = v_t + (u * v_x + v * v_y) + p_y - 0.01 * (v_xx + v_yy)\n",
        "        f_e = 0.0\n",
        "\n",
        "        return u, v, p, f_u, f_v, f_e\n",
        "\n",
        "    def callback(self, loss):\n",
        "        print('Loss: %.3e' % loss)\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Training algorithms============================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "    def Adam_train(self, epochs=5000,file_save=''):\n",
        "\n",
        "        start_time = time.time()\n",
        "        \n",
        "        self.dom_no=math.ceil(self.N_train/self.batch_size)\n",
        "        self.init_no=math.ceil(self.data_t0.shape[0]/self.batch_size)\n",
        "        self.bound_no=math.ceil((self.data_sup_b_train.shape[0]/4)/self.batch_size)\n",
        "        \n",
        "        self.i_mul=math.ceil(self.dom_no/self.init_no)\n",
        "        self.b_mul=math.ceil(self.dom_no/self.bound_no)\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            # iterating over all the batches \n",
        "            for bat in range(self.dom_no):\n",
        "                \n",
        "                # call batches here \n",
        "                d_batch = self.domain_batches (self.batch_size)[bat][0]\n",
        "                i_batch = np.asarray((self.ic_batches(self.batch_size)*self.i_mul),dtype=object)[bat][0]\n",
        "                b_batch1 = np.asarray((self.bc_batches(self.batch_size,1)*self.b_mul),dtype=object)[bat][0]\n",
        "                b_batch2 = np.asarray((self.bc_batches(self.batch_size,2)*self.b_mul),dtype=object)[bat][0]\n",
        "                b_batch3 = np.asarray((self.bc_batches(self.batch_size,3)*self.b_mul),dtype=object)[bat][0]\n",
        "                b_batch4 = np.asarray((self.bc_batches(self.batch_size,4)*self.b_mul),dtype=object)[bat][0]\n",
        "                \n",
        "                self.tf_dict = {\n",
        "                      self.x_ini_tf: i_batch[:,0:1] , \n",
        "                      self.y_ini_tf: i_batch[:,1:2] ,\n",
        "                      self.t_ini_tf: i_batch[:,2:3] , \n",
        "                      self.u_ini_tf: i_batch[:,3:4],\n",
        "                      self.v_ini_tf: i_batch[:,4:5] , \n",
        "\n",
        "                      self.x_bc1_tf: b_batch1[:,0:1] ,\n",
        "                      self.y_bc1_tf: b_batch1[:,1:2] , \n",
        "                      self.t_bc1_tf: b_batch1[:,2:3] ,\n",
        "                      self.U_bc1_tf: b_batch1[:,3:5] ,\n",
        "\n",
        "                      self.x_bc2_tf: b_batch2[:,0:1] ,\n",
        "                      self.y_bc2_tf: b_batch2[:,1:2] , \n",
        "                      self.t_bc2_tf: b_batch2[:,2:3] ,\n",
        "                      self.U_bc2_tf: b_batch1[:,3:5] ,\n",
        "\n",
        "                      self.x_bc3_tf: b_batch3[:,0:1] ,\n",
        "                      self.y_bc3_tf: b_batch3[:,1:2] , \n",
        "                      self.t_bc3_tf: b_batch3[:,2:3] ,\n",
        "                      self.U_bc3_tf: b_batch1[:,3:5] ,\n",
        "\n",
        "                      self.x_bc4_tf: b_batch4[:,0:1] ,\n",
        "                      self.y_bc4_tf: b_batch4[:,1:2] , \n",
        "                      self.t_bc4_tf: b_batch4[:,2:3] ,\n",
        "                      self.U_bc4_tf: b_batch1[:,3:5] ,\n",
        "\n",
        "                      self.x_tf: d_batch[:,0:1] , \n",
        "                      self.y_tf:d_batch[:,1:2] , \n",
        "                      self.t_tf:d_batch[:,2:3]} \n",
        "\n",
        "    \n",
        "                # add the tf dict here \n",
        "                self.sess.run(self.train_op_Adam, self.tf_dict)\n",
        "\n",
        "            # Print\n",
        "            if epoch % 10 == 0:\n",
        "                \n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, self.tf_dict)\n",
        "                loss_b_value,loss_i_value, loss_r_value = self.sess.run([self.loss_bcs,self.loss_ics, self.loss_res], self.tf_dict)\n",
        "                \n",
        "                # logging the loss values\n",
        "                                \n",
        "                \n",
        "#                 adaptive_constant_bcs_val=self.sess.run(self.adaptive_constant_bcs,tf_dict)\n",
        "#                 adaptive_constant_ics_val=self.sess.run(self.adpative_constant_ics,tf_dict)\n",
        "\n",
        "#                 self.adaptive_constant_bcs_val=adaptive_constant_bcs_val* (1.0-self.beta)+self.beta*self.adaptive_constant_bcs_val\n",
        "#                 self.adaptive_constant_ics_val=adaptive_constant_ics_val* (1.0-self.beta)+self.beta*self.adaptive_constant_ics_val\n",
        "\n",
        "                self.loss_bcs_log.append(loss_b_value)\n",
        "                self.loss_ics_log.append(loss_i_value)\n",
        "                self.loss_res_log.append(loss_r_value)\n",
        "\n",
        "                print('epoch: %d, Loss: %.3e, Time: %.2f' %\n",
        "                      (epoch, loss_value, elapsed))\n",
        "#                 print(\"constant_bcs_val: {:.3f}\".format(self.adaptive_constant_bcs_val))\n",
        "#                 print(\"constant_ics_val: {:.3f}\".format(self.adaptive_constant_ics_val))\n",
        "                \n",
        "#                 file=open(file_path,\"w\")\n",
        "#                 file.writelines(\"epoch: \"+str(epoch)+\" \"+\"\\n\"+\"loss: \"+str(loss_value)+\"\\n\"+\" elapsed: \"+str(elapsed))#+\"\\n\"+\"bcs: \"+str(self.adaptive_constant_bcs_val)+\" ics: \"+str(self.adaptive_constant_bcs_val)+\"\\n\")\n",
        "#                 file.flush()\n",
        "                start_time = time.time()                \n",
        "                start_time = time.time()\n",
        "            \n",
        "            if epoch !=0 and epoch %1000==0:\n",
        "                self.save_parameters(file_save)\n",
        "\n",
        "#     def Adam_train(self, epochs=5000,file_save='',file_path=''):\n",
        "#         # load data everytime here for a sample, \n",
        "#         start_time = time.time()\n",
        "#         tf_dict = {\n",
        "#               self.x_ini_tf: self.data_t0[:,0:1], # Initial values\n",
        "#               self.y_ini_tf: self.data_t0[:,1:2],\n",
        "#               self.t_ini_tf: self.data_t0[:,2:3], \n",
        "#               self.u_ini_tf: self.data_t0[:,3:4],\n",
        "#               self.v_ini_tf: self.data_t0[:,4:5], \n",
        "\n",
        "#               self.x_bc1_tf: self.data_sup_b_train[0:20000,0:1] ,# boundary conditions\n",
        "#               self.y_bc1_tf: self.data_sup_b_train[0:20000,1:2], \n",
        "#               self.t_bc1_tf: self.data_sup_b_train[0:20000,2:3],\n",
        "#               self.U_bc1_tf: self.data_sup_b_train[0:20000,3:5],\n",
        "\n",
        "#               self.x_bc2_tf: self.data_sup_b_train[20000:40000,0:1] ,\n",
        "#               self.y_bc2_tf: self.data_sup_b_train[20000:40000,1:2] , \n",
        "#               self.t_bc2_tf: self.data_sup_b_train[20000:40000,2:3] ,\n",
        "#               self.U_bc2_tf: self.data_sup_b_train[20000:40000,3:5] ,\n",
        "\n",
        "#               self.x_bc3_tf: self.data_sup_b_train[40000:60000,0:1] ,\n",
        "#               self.y_bc3_tf: self.data_sup_b_train[40000:60000,1:2] , \n",
        "#               self.t_bc3_tf: self.data_sup_b_train[40000:60000,2:3] ,\n",
        "#               self.U_bc3_tf: self.data_sup_b_train[40000:60000,3:5] ,\n",
        "\n",
        "#               self.x_bc4_tf: self.data_sup_b_train[60000:80000,0:1] ,\n",
        "#               self.y_bc4_tf: self.data_sup_b_train[60000:80000,1:2] , \n",
        "#               self.t_bc4_tf: self.data_sup_b_train[60000:80000,2:3] ,\n",
        "#               self.U_bc4_tf: self.data_sup_b_train[60000:80000,3:5] ,\n",
        "\n",
        "#               self.x_tf: self.data_idx[:,0:1] , # domain \n",
        "#               self.y_tf: self.data_idx[:,1:2] , \n",
        "#               self.t_tf: self.data_idx[:,2:3] ,\n",
        "\n",
        "#               self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val,\n",
        "#               self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val}\n",
        "        \n",
        "#         for epoch in range(epochs):\n",
        "\n",
        "#             # add the tf dict here \n",
        "#             self.sess.run(self.train_op_Adam, tf_dict)\n",
        "\n",
        "#             # Print\n",
        "#             if epoch % 10 == 0:\n",
        "#                 elapsed = time.time() - start_time\n",
        "#                 loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                \n",
        "#                 # logging the loss values\n",
        "#                 bc_loss,ic_loss,res_loss=self.log_loss(tf_dict)\n",
        "                \n",
        "#                 # using the adaptive weighting constants\n",
        "#                 adaptive_constant_bcs_val=self.sess.run(self.adaptive_constant_bcs,tf_dict)\n",
        "#                 adaptive_constant_ics_val=self.sess.run(self.adpative_constant_ics,tf_dict)\n",
        "\n",
        "#                 self.adaptive_constant_bcs_val=adaptive_constant_bcs_val* (1.0-self.beta)+self.beta*self.adaptive_constant_bcs_val\n",
        "#                 self.adaptive_constant_ics_val=adaptive_constant_ics_val* (1.0-self.beta)+self.beta*self.adaptive_constant_ics_val\n",
        "\n",
        "#                 print('epoch: %d, Loss: %.3e, Time: %.2f' %\n",
        "#                       (epoch, loss_value, elapsed))\n",
        "#                 print(\"constant_bcs_val: {:.3f}\".format(self.adaptive_constant_bcs_val))\n",
        "#                 print(\"constant_ics_val: {:.3f}\".format(self.adaptive_constant_ics_val))\n",
        "                \n",
        "#                 file=open(file_path,\"w\")\n",
        "#                 file.writelines(\"epoch: \"+str(epoch)+\" \"+\"\\n\"+\"loss: \"+str(loss_value)+\"\\n\"+\" elapsed: \"+str(elapsed)+\"\\n\"+\"bcs: \"+str(self.adaptive_constant_bcs_val)+\" ics: \"+str(self.adaptive_constant_bcs_val)+\"\\n\")\n",
        "#                 file.flush()\n",
        "#                 start_time = time.time()\n",
        "            \n",
        "#             if epoch !=0 and epoch %1000==0:\n",
        "#                self.save_parameters(file_save)\n",
        "\n",
        "# two step train BFGS used to finetune the result\n",
        "    def BFGS_train(self):\n",
        "\n",
        "        tf_dict = {\n",
        "              self.x_ini_tf: self.data_t0[:,0:1], # Initial values\n",
        "              self.y_ini_tf: self.data_t0[:,1:2],\n",
        "              self.t_ini_tf: self.data_t0[:,2:3], \n",
        "              self.u_ini_tf: self.data_t0[:,3:4],\n",
        "              self.v_ini_tf: self.data_t0[:,4:5], \n",
        "\n",
        "              self.x_bc1_tf: self.data_sup_b_train[0:20000,0:1] ,# boundary conditions\n",
        "              self.y_bc1_tf: self.data_sup_b_train[0:20000,1:2], \n",
        "              self.t_bc1_tf: self.data_sup_b_train[0:20000,2:3],\n",
        "              self.U_bc1_tf: self.data_sup_b_train[0:20000,3:5],\n",
        "\n",
        "              self.x_bc2_tf: self.data_sup_b_train[20000:40000,0:1] ,\n",
        "              self.y_bc2_tf: self.data_sup_b_train[20000:40000,1:2] , \n",
        "              self.t_bc2_tf: self.data_sup_b_train[20000:40000,2:3] ,\n",
        "              self.U_bc2_tf: self.data_sup_b_train[20000:40000,3:5] ,\n",
        "\n",
        "              self.x_bc3_tf: self.data_sup_b_train[40000:60000,0:1] ,\n",
        "              self.y_bc3_tf: self.data_sup_b_train[40000:60000,1:2] , \n",
        "              self.t_bc3_tf: self.data_sup_b_train[40000:60000,2:3] ,\n",
        "              self.U_bc3_tf: self.data_sup_b_train[40000:60000,3:5] ,\n",
        "\n",
        "              self.x_bc4_tf: self.data_sup_b_train[60000:80000,0:1] ,\n",
        "              self.y_bc4_tf: self.data_sup_b_train[60000:80000,1:2] , \n",
        "              self.t_bc4_tf: self.data_sup_b_train[60000:80000,2:3] ,\n",
        "              self.U_bc4_tf: self.data_sup_b_train[60000:80000,3:5] ,\n",
        "\n",
        "              self.x_tf: self.data_idx[:,0:1] , # domain \n",
        "              self.y_tf: self.data_idx[:,1:2] , \n",
        "              self.t_tf: self.data_idx[:,2:3] ,\n",
        "\n",
        "              self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val,\n",
        "              self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val}\n",
        "\n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict=tf_dict,\n",
        "                                fetches=[self.loss],\n",
        "                                loss_callback=self.callback)\n",
        "\n",
        "#============================================================================================================================#\n",
        "#=============================================Predicting for test_data=======================================================#\n",
        "#============================================================================================================================#\n",
        "\n",
        "\n",
        "    def predict(self, x_star, y_star, t_star):\n",
        "\n",
        "        tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
        "\n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        v_star = self.sess.run(self.v_pred, tf_dict)\n",
        "        p_star = self.sess.run(self.p_pred, tf_dict)\n",
        "\n",
        "        return u_star, v_star, p_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b-M-h1EcJvE"
      },
      "outputs": [],
      "source": [
        "def dom_data(N_train,T,min_max):\n",
        "    xmax,xmin,ymax,ymin,tmax,tmin=min_max\n",
        "\n",
        "    num_pts=int(N_train/T) # Gives the number of points per time step to be included in training dataset\n",
        "    data_idx=np.zeros((N_train,3)) # stores the \n",
        "\n",
        "    for i in range(len(data_idx)):\n",
        "        data_idx[i,0:2]=[float(np.random.uniform(xmin,xmax,1)),float(np.random.uniform(ymin,ymax,1))]\n",
        "\n",
        "    j=0\n",
        "    for i in range(0,len(data_idx),num_pts):\n",
        "        data_idx[i:i+num_pts,2:3]=j\n",
        "        i=i+1\n",
        "        j=j+0.1\n",
        "\n",
        "    return data_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBX2_H75gmmY"
      },
      "outputs": [],
      "source": [
        "def load_data(N_train):\n",
        "    # Load Data\n",
        "    path=r\"C:\\Users\\vamsi_oe20s302\\Downloads\\all_pressures\"\n",
        "    #path=r\"C:\\Users\\Vamsi\\Downloads\\all_pressures\"\n",
        "    uvel=pd.read_csv(path+r\"/u_vel.csv\")\n",
        "    uvel=uvel.to_numpy()\n",
        "\n",
        "    vvel=pd.read_csv(path+r\"/v_vel.csv\")\n",
        "    vvel=vvel.to_numpy()\n",
        "\n",
        "    press=pd.read_csv(path+r\"/static_press.csv\")\n",
        "    press=press.to_numpy()\n",
        "\n",
        "    xy=pd.read_csv(path+r\"/xy.csv\")\n",
        "    xy=xy.to_numpy()\n",
        "\n",
        "    t=pd.read_csv(path+r\"/time.csv\")\n",
        "    t=t.to_numpy()\n",
        "\n",
        "    N=xy.shape[0]\n",
        "    T=t.shape[0]\n",
        "    \n",
        "\n",
        "    XX = np.tile(xy[:,0:1], (1,T)) # N x T\n",
        "    YY = np.tile(xy[:,1:2], (1,T)) # N x T\n",
        "    TT = np.tile(t, (1,N)).T # N x T\n",
        "\n",
        "    x = XX.flatten()[:,None] # NT x 1\n",
        "    y = YY.flatten()[:,None] # NT x 1\n",
        "    t = TT.flatten()[:,None] # NT x 1\n",
        "\n",
        "    u = uvel.flatten()[:,None] # NT x 1\n",
        "    v = vvel.flatten()[:,None] # NT x 1\n",
        "    p = press.flatten()[:,None] # NT x 1\n",
        "\n",
        "# Extracting the unique parts of x,y,t\n",
        "    ax=np.unique(x)\n",
        "    xmin=min(ax)\n",
        "    xmax=max(ax)\n",
        "\n",
        "    ay=np.unique(y)\n",
        "    ymin=min(ay)\n",
        "    ymax=max(ay)\n",
        "    \n",
        "    at=np.unique(t)\n",
        "    tmin=min(at)\n",
        "    tmax=max(at)\n",
        "\n",
        "    # Concatenating all the points\n",
        "    data1=np.concatenate([x ,y ,t , u , v ,p ],1)\n",
        "\n",
        "    data2=data1[:,:][data1[:,2]<=20]\n",
        "    data3=data2[:,:][data2[:,0]>=xmin]\n",
        "    data4=data3[:,:][data3[:,0]<=xmax]\n",
        "    data5=data4[:,:][data4[:,1]>=ymin]\n",
        "\n",
        "    # Creating domain dataset size= (2000000,6)\n",
        "    # It is from this dataset, we extract idx points for calculating the NS residual\n",
        "    data_domain=data5[:,:][data5[:,1]<=ymax]\n",
        "\n",
        "    # Creating initial condition dataset size=(10000,6)\n",
        "    data_t0=data_domain[:,:][data_domain[:,2]==0]\n",
        "\n",
        "    # Defining boundary conditions for the data\n",
        "    bc1_data=data_domain[:,:][data_domain[:,1]==ymax]\n",
        "    bc2_data=data_domain[:,:][data_domain[:,0]==xmin]\n",
        "    bc3_data=data_domain[:,:][data_domain[:,0]==xmax]\n",
        "    bc4_data=data_domain[:,:][data_domain[:,1]==ymin]\n",
        "\n",
        "    # Creating boundary conditions dataset size=(80000,6)\n",
        "    data_sup_b_train = np.concatenate([bc1_data,bc2_data,bc3_data,bc4_data], 0)\n",
        "\n",
        "    \n",
        "    # Extracting random points(x,y,t) from the domain dataset\n",
        "    min_max=[xmax,xmin,ymax,ymin,tmax,tmin]\n",
        "    \n",
        "    data_idx=dom_data(N_train,T,min_max)\n",
        "    \n",
        "    return data_idx,data_t0,data_sup_b_train\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCYYbrLulb9S",
        "outputId": "3f3969eb-2b6c-4302-e9b4-04e52083269b",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro P620, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13564\\892530896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#file_path=r\"C:\\Users\\Vamsi\\Downloads\\tf_test.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#      Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;31m#model.BFGS_train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13564\\875906667.py\u001b[0m in \u001b[0;36mAdam_train\u001b[1;34m(self, epochs, file_save)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                 \u001b[1;31m# add the tf dict here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op_Adam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;31m# Print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    N_train = 140000 \n",
        "    batch_size= 128\n",
        "\n",
        "    layers = [3, 50,50,50, 2]\n",
        "    #layers=[3]+10*[4*50]+[2]\n",
        "    \n",
        "    # loading data\n",
        "    data_idx,data_t0,data_sup_b_train = load_data(N_train)\n",
        "    \n",
        "    # Initializing the model for training\n",
        "    model = pinn(data_idx,data_t0,data_sup_b_train,layers,N_train,batch_size,load=False,file=None)\n",
        "    \n",
        "#     # Initializing model for testing by loading the pickle file\n",
        "#     filedr='params_112' # Enter the name of the pickle file\n",
        "#     model= pinn(data_idx,data_t0,data_sup_b_train,layers,N_train,batch_size,load=True,file=filedr)\n",
        "    \n",
        "#     Enter the name of the parameters file\n",
        "    file_save='params_112' \n",
        "    #file_path=r\"C:\\Users\\Vamsi\\Downloads\\tf_test.txt\"\n",
        "#      Training the model\n",
        "    model.Adam_train(10,file_save)\n",
        "    #model.BFGS_train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-NRluyGcJvL",
        "outputId": "0dea14bf-0156-4788-8e9e-0375cfc89fb7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{<tf.Tensor 'Placeholder_34:0' shape=(?, 1) dtype=float32>: array([[0.44261744],\n",
            "       [0.44846324],\n",
            "       [0.45430903],\n",
            "       [0.46015483],\n",
            "       [0.46600063],\n",
            "       [0.47184643],\n",
            "       [0.47769223],\n",
            "       [0.48353802],\n",
            "       [0.48938382],\n",
            "       [0.49522962],\n",
            "       [0.50107542],\n",
            "       [0.50692122],\n",
            "       [0.51276702],\n",
            "       [0.51861281],\n",
            "       [0.52445861],\n",
            "       [0.53030441],\n",
            "       [0.53615021],\n",
            "       [0.54199601],\n",
            "       [0.54784181],\n",
            "       [0.5536876 ],\n",
            "       [0.5595334 ],\n",
            "       [0.5653792 ],\n",
            "       [0.571225  ],\n",
            "       [0.5770708 ],\n",
            "       [0.58291659],\n",
            "       [0.58876239],\n",
            "       [0.59460819],\n",
            "       [0.60045399],\n",
            "       [0.60629979],\n",
            "       [0.61214559],\n",
            "       [0.61799138],\n",
            "       [0.62383718],\n",
            "       [0.62968298],\n",
            "       [0.63552878],\n",
            "       [0.64137458],\n",
            "       [0.64722038],\n",
            "       [0.65306617],\n",
            "       [0.65891197],\n",
            "       [0.66475777],\n",
            "       [0.67060357],\n",
            "       [0.67644937],\n",
            "       [0.68229516],\n",
            "       [0.68814096],\n",
            "       [0.69398676],\n",
            "       [0.69983256],\n",
            "       [0.70567836],\n",
            "       [0.71152416],\n",
            "       [0.71736995],\n",
            "       [0.72321575],\n",
            "       [0.72906155],\n",
            "       [0.73490735],\n",
            "       [0.74075315],\n",
            "       [0.74659895],\n",
            "       [0.75244474],\n",
            "       [0.75829054],\n",
            "       [0.76413634],\n",
            "       [0.76998214],\n",
            "       [0.77582794],\n",
            "       [0.78167373],\n",
            "       [0.78751953],\n",
            "       [0.20878551],\n",
            "       [0.21463131],\n",
            "       [0.2204771 ],\n",
            "       [0.2263229 ],\n",
            "       [0.2321687 ],\n",
            "       [0.2380145 ],\n",
            "       [0.2438603 ],\n",
            "       [0.24970609],\n",
            "       [0.25555189],\n",
            "       [0.26139769],\n",
            "       [0.26724349],\n",
            "       [0.27308929],\n",
            "       [0.27893509],\n",
            "       [0.28478088],\n",
            "       [0.29062668],\n",
            "       [0.29647248],\n",
            "       [0.30231828],\n",
            "       [0.30816408],\n",
            "       [0.31400988],\n",
            "       [0.31985567],\n",
            "       [0.32570147],\n",
            "       [0.33154727],\n",
            "       [0.33739307],\n",
            "       [0.34323887],\n",
            "       [0.34908466],\n",
            "       [0.35493046],\n",
            "       [0.36077626],\n",
            "       [0.36662206],\n",
            "       [0.37246786],\n",
            "       [0.37831366],\n",
            "       [0.38415945],\n",
            "       [0.39000525],\n",
            "       [0.39585105],\n",
            "       [0.40169685],\n",
            "       [0.40754265],\n",
            "       [0.41338845],\n",
            "       [0.41923424],\n",
            "       [0.42508004],\n",
            "       [0.43092584],\n",
            "       [0.43677164],\n",
            "       [0.44261744],\n",
            "       [0.44846324],\n",
            "       [0.45430903],\n",
            "       [0.46015483],\n",
            "       [0.46600063],\n",
            "       [0.47184643],\n",
            "       [0.47769223],\n",
            "       [0.48353802],\n",
            "       [0.48938382],\n",
            "       [0.49522962],\n",
            "       [0.50107542],\n",
            "       [0.50692122],\n",
            "       [0.51276702],\n",
            "       [0.51861281],\n",
            "       [0.52445861],\n",
            "       [0.53030441],\n",
            "       [0.53615021],\n",
            "       [0.54199601],\n",
            "       [0.54784181],\n",
            "       [0.5536876 ],\n",
            "       [0.5595334 ],\n",
            "       [0.5653792 ],\n",
            "       [0.571225  ],\n",
            "       [0.5770708 ],\n",
            "       [0.58291659],\n",
            "       [0.58876239],\n",
            "       [0.59460819],\n",
            "       [0.60045399]]), <tf.Tensor 'Placeholder_35:0' shape=(?, 1) dtype=float32>: array([[-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.25130029],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032],\n",
            "       [-0.24501032]]), <tf.Tensor 'Placeholder_36:0' shape=(?, 1) dtype=float32>: array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]]), <tf.Tensor 'Placeholder_37:0' shape=(?, 1) dtype=float32>: array([[1.09879335],\n",
            "       [1.09006427],\n",
            "       [1.09006427],\n",
            "       [1.08585519],\n",
            "       [1.08585519],\n",
            "       [1.08244898],\n",
            "       [1.07849559],\n",
            "       [1.07849559],\n",
            "       [1.07019134],\n",
            "       [1.06597687],\n",
            "       [1.06138402],\n",
            "       [1.06138402],\n",
            "       [1.05598006],\n",
            "       [1.05598006],\n",
            "       [1.04876806],\n",
            "       [1.04246079],\n",
            "       [1.03580025],\n",
            "       [1.03580025],\n",
            "       [1.02877799],\n",
            "       [1.02877799],\n",
            "       [1.02063565],\n",
            "       [1.01588566],\n",
            "       [1.01142544],\n",
            "       [1.00897713],\n",
            "       [1.00294404],\n",
            "       [0.99880795],\n",
            "       [0.99512069],\n",
            "       [0.9912915 ],\n",
            "       [0.98365402],\n",
            "       [0.98365402],\n",
            "       [0.97884198],\n",
            "       [0.97244824],\n",
            "       [0.97140372],\n",
            "       [0.96549055],\n",
            "       [0.96549055],\n",
            "       [0.96457572],\n",
            "       [0.95891247],\n",
            "       [0.95850807],\n",
            "       [0.95233233],\n",
            "       [0.95432252],\n",
            "       [0.94832058],\n",
            "       [0.95034887],\n",
            "       [0.9459858 ],\n",
            "       [0.9459858 ],\n",
            "       [0.94650822],\n",
            "       [0.94162825],\n",
            "       [0.94332148],\n",
            "       [0.94330793],\n",
            "       [0.94330793],\n",
            "       [0.94335322],\n",
            "       [0.94430259],\n",
            "       [0.93913484],\n",
            "       [0.94263681],\n",
            "       [0.94263681],\n",
            "       [0.94748738],\n",
            "       [0.95494559],\n",
            "       [0.95423083],\n",
            "       [0.95423083],\n",
            "       [0.95417708],\n",
            "       [0.96437075],\n",
            "       [1.06145864],\n",
            "       [1.05851059],\n",
            "       [1.05851059],\n",
            "       [1.05851059],\n",
            "       [1.05780826],\n",
            "       [1.05780826],\n",
            "       [1.05857024],\n",
            "       [1.05857024],\n",
            "       [1.05857024],\n",
            "       [1.06104203],\n",
            "       [1.06104203],\n",
            "       [1.06227983],\n",
            "       [1.06227983],\n",
            "       [1.06404092],\n",
            "       [1.06714677],\n",
            "       [1.06714677],\n",
            "       [1.07021896],\n",
            "       [1.07302161],\n",
            "       [1.07302161],\n",
            "       [1.0765509 ],\n",
            "       [1.08006993],\n",
            "       [1.08006993],\n",
            "       [1.08305352],\n",
            "       [1.08828243],\n",
            "       [1.09144567],\n",
            "       [1.09144567],\n",
            "       [1.09397623],\n",
            "       [1.09397623],\n",
            "       [1.09613099],\n",
            "       [1.09613099],\n",
            "       [1.09830279],\n",
            "       [1.09830279],\n",
            "       [1.10011476],\n",
            "       [1.10011476],\n",
            "       [1.10062934],\n",
            "       [1.10062934],\n",
            "       [1.1011874 ],\n",
            "       [1.1011874 ],\n",
            "       [1.09935654],\n",
            "       [1.09879335],\n",
            "       [1.09879335],\n",
            "       [1.09871717],\n",
            "       [1.09276   ],\n",
            "       [1.09276   ],\n",
            "       [1.09039776],\n",
            "       [1.08244898],\n",
            "       [1.07849559],\n",
            "       [1.07849559],\n",
            "       [1.07414218],\n",
            "       [1.06973803],\n",
            "       [1.06973803],\n",
            "       [1.06334966],\n",
            "       [1.05598006],\n",
            "       [1.04982893],\n",
            "       [1.04982893],\n",
            "       [1.0428702 ],\n",
            "       [1.0428702 ],\n",
            "       [1.03548046],\n",
            "       [1.02877799],\n",
            "       [1.02063565],\n",
            "       [1.02063565],\n",
            "       [1.0142649 ],\n",
            "       [1.01142544],\n",
            "       [1.00671246],\n",
            "       [1.00294404],\n",
            "       [0.99512069],\n",
            "       [0.99512069],\n",
            "       [0.98911544]]), <tf.Tensor 'Placeholder_38:0' shape=(?, 1) dtype=float32>: array([[ 0.04730172],\n",
            "       [ 0.05214543],\n",
            "       [ 0.05214543],\n",
            "       [ 0.05921827],\n",
            "       [ 0.05921827],\n",
            "       [ 0.06599698],\n",
            "       [ 0.07228677],\n",
            "       [ 0.07228677],\n",
            "       [ 0.07079034],\n",
            "       [ 0.07556781],\n",
            "       [ 0.08007288],\n",
            "       [ 0.08007288],\n",
            "       [ 0.08434909],\n",
            "       [ 0.08434909],\n",
            "       [ 0.08135521],\n",
            "       [ 0.08445333],\n",
            "       [ 0.08704198],\n",
            "       [ 0.08704198],\n",
            "       [ 0.08924853],\n",
            "       [ 0.08924853],\n",
            "       [ 0.09001128],\n",
            "       [ 0.08314456],\n",
            "       [ 0.08773026],\n",
            "       [ 0.08219062],\n",
            "       [ 0.08481986],\n",
            "       [ 0.07756654],\n",
            "       [ 0.08336448],\n",
            "       [ 0.07583309],\n",
            "       [ 0.07337841],\n",
            "       [ 0.07337841],\n",
            "       [ 0.06841035],\n",
            "       [ 0.06923378],\n",
            "       [ 0.06164496],\n",
            "       [ 0.06093744],\n",
            "       [ 0.06093744],\n",
            "       [ 0.0542955 ],\n",
            "       [ 0.05339315],\n",
            "       [ 0.04617284],\n",
            "       [ 0.0435694 ],\n",
            "       [ 0.03649081],\n",
            "       [ 0.03566889],\n",
            "       [ 0.0270631 ],\n",
            "       [ 0.02263996],\n",
            "       [ 0.02263996],\n",
            "       [ 0.01571362],\n",
            "       [ 0.0109392 ],\n",
            "       [ 0.00364456],\n",
            "       [-0.00317606],\n",
            "       [-0.00317606],\n",
            "       [-0.01008646],\n",
            "       [-0.01710121],\n",
            "       [-0.02398607],\n",
            "       [-0.03190072],\n",
            "       [-0.03190072],\n",
            "       [-0.03948748],\n",
            "       [-0.04476369],\n",
            "       [-0.05371954],\n",
            "       [-0.05371954],\n",
            "       [-0.06231302],\n",
            "       [-0.06605729],\n",
            "       [-0.00049737],\n",
            "       [-0.00098275],\n",
            "       [-0.00098275],\n",
            "       [-0.00098275],\n",
            "       [-0.00392041],\n",
            "       [-0.00392041],\n",
            "       [-0.00707286],\n",
            "       [-0.00707286],\n",
            "       [-0.00707286],\n",
            "       [-0.00937688],\n",
            "       [-0.00937688],\n",
            "       [-0.01189243],\n",
            "       [-0.01189243],\n",
            "       [-0.01388614],\n",
            "       [-0.01346503],\n",
            "       [-0.01346503],\n",
            "       [-0.01348049],\n",
            "       [-0.01607173],\n",
            "       [-0.01607173],\n",
            "       [-0.01438057],\n",
            "       [-0.01207371],\n",
            "       [-0.01207371],\n",
            "       [-0.00895216],\n",
            "       [-0.01095563],\n",
            "       [-0.00676544],\n",
            "       [-0.00676544],\n",
            "       [-0.00165065],\n",
            "       [-0.00165065],\n",
            "       [ 0.00406238],\n",
            "       [ 0.00406238],\n",
            "       [ 0.01031568],\n",
            "       [ 0.01031568],\n",
            "       [ 0.01739286],\n",
            "       [ 0.01739286],\n",
            "       [ 0.02552087],\n",
            "       [ 0.02552087],\n",
            "       [ 0.03374707],\n",
            "       [ 0.03374707],\n",
            "       [ 0.04054039],\n",
            "       [ 0.04730172],\n",
            "       [ 0.04730172],\n",
            "       [ 0.05470933],\n",
            "       [ 0.05908492],\n",
            "       [ 0.05908492],\n",
            "       [ 0.06589829],\n",
            "       [ 0.06599698],\n",
            "       [ 0.07228677],\n",
            "       [ 0.07228677],\n",
            "       [ 0.07757296],\n",
            "       [ 0.08354373],\n",
            "       [ 0.08354373],\n",
            "       [ 0.08655848],\n",
            "       [ 0.08434909],\n",
            "       [ 0.08868827],\n",
            "       [ 0.08868827],\n",
            "       [ 0.09248323],\n",
            "       [ 0.09248323],\n",
            "       [ 0.09546473],\n",
            "       [ 0.08924853],\n",
            "       [ 0.09001128],\n",
            "       [ 0.09001128],\n",
            "       [ 0.09336586],\n",
            "       [ 0.08773026],\n",
            "       [ 0.09271443],\n",
            "       [ 0.08481986],\n",
            "       [ 0.08336448],\n",
            "       [ 0.08336448],\n",
            "       [ 0.08290117]]), <tf.Tensor 'Placeholder_39:0' shape=(?, 1) dtype=float32>: array([[0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181]]), <tf.Tensor 'Placeholder_40:0' shape=(?, 1) dtype=float32>: array([[0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609],\n",
            "       [0.33366609]]), <tf.Tensor 'Placeholder_41:0' shape=(?, 1) dtype=float32>: array([[ 4.8],\n",
            "       [ 4.9],\n",
            "       [ 5. ],\n",
            "       [ 5.1],\n",
            "       [ 5.2],\n",
            "       [ 5.3],\n",
            "       [ 5.4],\n",
            "       [ 5.5],\n",
            "       [ 5.6],\n",
            "       [ 5.7],\n",
            "       [ 5.8],\n",
            "       [ 5.9],\n",
            "       [ 6. ],\n",
            "       [ 6.1],\n",
            "       [ 6.2],\n",
            "       [ 6.3],\n",
            "       [ 6.4],\n",
            "       [ 6.5],\n",
            "       [ 6.6],\n",
            "       [ 6.7],\n",
            "       [ 6.8],\n",
            "       [ 6.9],\n",
            "       [ 7. ],\n",
            "       [ 7.1],\n",
            "       [ 7.2],\n",
            "       [ 7.3],\n",
            "       [ 7.4],\n",
            "       [ 7.5],\n",
            "       [ 7.6],\n",
            "       [ 7.7],\n",
            "       [ 7.8],\n",
            "       [ 7.9],\n",
            "       [ 8. ],\n",
            "       [ 8.1],\n",
            "       [ 8.2],\n",
            "       [ 8.3],\n",
            "       [ 8.4],\n",
            "       [ 8.5],\n",
            "       [ 8.6],\n",
            "       [ 8.7],\n",
            "       [ 8.8],\n",
            "       [ 8.9],\n",
            "       [ 9. ],\n",
            "       [ 9.1],\n",
            "       [ 9.2],\n",
            "       [ 9.3],\n",
            "       [ 9.4],\n",
            "       [ 9.5],\n",
            "       [ 9.6],\n",
            "       [ 9.7],\n",
            "       [ 9.8],\n",
            "       [ 9.9],\n",
            "       [10. ],\n",
            "       [10.1],\n",
            "       [10.2],\n",
            "       [10.3],\n",
            "       [10.4],\n",
            "       [10.5],\n",
            "       [10.6],\n",
            "       [10.7],\n",
            "       [10.8],\n",
            "       [10.9],\n",
            "       [11. ],\n",
            "       [11.1],\n",
            "       [11.2],\n",
            "       [11.3],\n",
            "       [11.4],\n",
            "       [11.5],\n",
            "       [11.6],\n",
            "       [11.7],\n",
            "       [11.8],\n",
            "       [11.9],\n",
            "       [12. ],\n",
            "       [12.1],\n",
            "       [12.2],\n",
            "       [12.3],\n",
            "       [12.4],\n",
            "       [12.5],\n",
            "       [12.6],\n",
            "       [12.7],\n",
            "       [12.8],\n",
            "       [12.9],\n",
            "       [13. ],\n",
            "       [13.1],\n",
            "       [13.2],\n",
            "       [13.3],\n",
            "       [13.4],\n",
            "       [13.5],\n",
            "       [13.6],\n",
            "       [13.7],\n",
            "       [13.8],\n",
            "       [13.9],\n",
            "       [14. ],\n",
            "       [14.1],\n",
            "       [14.2],\n",
            "       [14.3],\n",
            "       [14.4],\n",
            "       [14.5],\n",
            "       [14.6],\n",
            "       [14.7],\n",
            "       [14.8],\n",
            "       [14.9],\n",
            "       [15. ],\n",
            "       [15.1],\n",
            "       [15.2],\n",
            "       [15.3],\n",
            "       [15.4],\n",
            "       [15.5],\n",
            "       [15.6],\n",
            "       [15.7],\n",
            "       [15.8],\n",
            "       [15.9],\n",
            "       [16. ],\n",
            "       [16.1],\n",
            "       [16.2],\n",
            "       [16.3],\n",
            "       [16.4],\n",
            "       [16.5],\n",
            "       [16.6],\n",
            "       [16.7],\n",
            "       [16.8],\n",
            "       [16.9],\n",
            "       [17. ],\n",
            "       [17.1],\n",
            "       [17.2],\n",
            "       [17.3],\n",
            "       [17.4],\n",
            "       [17.5]]), <tf.Tensor 'Placeholder_42:0' shape=(?, 2) dtype=float32>: array([[ 1.02761523,  0.01540928],\n",
            "       [ 1.00333232, -0.00475917],\n",
            "       [ 1.00748592, -0.03328337],\n",
            "       [ 1.03234096, -0.04481899],\n",
            "       [ 1.05715272, -0.02951888],\n",
            "       [ 1.05682196,  0.00218337],\n",
            "       [ 1.02723435,  0.01534674],\n",
            "       [ 1.00321268, -0.00510007],\n",
            "       [ 1.00768657, -0.03354352],\n",
            "       [ 1.03266855, -0.04479951],\n",
            "       [ 1.05733372, -0.02920314],\n",
            "       [ 1.05661016,  0.00250788],\n",
            "       [ 1.02685087,  0.01527862],\n",
            "       [ 1.00309366, -0.00544118],\n",
            "       [ 1.0078873 , -0.03380111],\n",
            "       [ 1.03299537, -0.04477678],\n",
            "       [ 1.05751172, -0.02888451],\n",
            "       [ 1.05639569,  0.00283004],\n",
            "       [ 1.02647189,  0.01520643],\n",
            "       [ 1.00298312, -0.00578314],\n",
            "       [ 1.00809477, -0.03405481],\n",
            "       [ 1.0333259 , -0.04474952],\n",
            "       [ 1.05768849, -0.02856331],\n",
            "       [ 1.05617795,  0.00315019],\n",
            "       [ 1.02609336,  0.01512916],\n",
            "       [ 1.00287478, -0.00612714],\n",
            "       [ 1.00830259, -0.03430758],\n",
            "       [ 1.03365312, -0.04471916],\n",
            "       [ 1.05785812, -0.02824024],\n",
            "       [ 1.05595276,  0.00346612],\n",
            "       [ 1.0257142 ,  0.01504717],\n",
            "       [ 1.00276917, -0.0064715 ],\n",
            "       [ 1.00851215, -0.03455684],\n",
            "       [ 1.03398096, -0.04468488],\n",
            "       [ 1.05802551, -0.02791433],\n",
            "       [ 1.05572566,  0.00378064],\n",
            "       [ 1.02533902,  0.01496073],\n",
            "       [ 1.00267076, -0.00681678],\n",
            "       [ 1.00872738, -0.0348035 ],\n",
            "       [ 1.03431053, -0.04464647],\n",
            "       [ 1.05819031, -0.02758603],\n",
            "       [ 1.05549431,  0.00409161],\n",
            "       [ 1.02496384,  0.01486936],\n",
            "       [ 1.00257411, -0.00716353],\n",
            "       [ 1.0089426 , -0.03504815],\n",
            "       [ 1.03463752, -0.04460507],\n",
            "       [ 1.05834855, -0.02725593],\n",
            "       [ 1.05525671,  0.00439952],\n",
            "       [ 1.02458892,  0.01477322],\n",
            "       [ 1.00248141, -0.00751073],\n",
            "       [ 1.0091607 , -0.03528979],\n",
            "       [ 1.03496552, -0.04455954],\n",
            "       [ 1.05850532, -0.02692339],\n",
            "       [ 1.0550175 ,  0.00470469],\n",
            "       [ 1.02421759,  0.01467304],\n",
            "       [ 1.00239462, -0.00785835],\n",
            "       [ 1.00938304, -0.03552895],\n",
            "       [ 1.03529421, -0.04451031],\n",
            "       [ 1.0586579 , -0.0265884 ],\n",
            "       [ 1.05477291,  0.00500645],\n",
            "       [ 1.02384592,  0.0145672 ],\n",
            "       [ 1.00230977, -0.00820724],\n",
            "       [ 1.00960531, -0.03576613],\n",
            "       [ 1.03562063, -0.04445799],\n",
            "       [ 1.05880538, -0.02625211],\n",
            "       [ 1.05452383,  0.00530499],\n",
            "       [ 1.02347593,  0.01445756],\n",
            "       [ 1.00222952, -0.00855596],\n",
            "       [ 1.00983124, -0.03600025],\n",
            "       [ 1.0359481 , -0.04440125],\n",
            "       [ 1.0589507 , -0.02591306],\n",
            "       [ 1.05427219,  0.00560047],\n",
            "       [ 1.02310868,  0.01434314],\n",
            "       [ 1.00215435, -0.00890521],\n",
            "       [ 1.01005988, -0.03623214],\n",
            "       [ 1.03627521, -0.04434127],\n",
            "       [ 1.05909147, -0.02557227],\n",
            "       [ 1.05401558,  0.00589236],\n",
            "       [ 1.02274145,  0.01422373],\n",
            "       [ 1.00208154, -0.00925516],\n",
            "       [ 1.0102895 , -0.03646155],\n",
            "       [ 1.03660056, -0.04427773],\n",
            "       [ 1.05922779, -0.02522998],\n",
            "       [ 1.05375509,  0.00618079],\n",
            "       [ 1.02237689,  0.01410023],\n",
            "       [ 1.00201387, -0.00960508],\n",
            "       [ 1.01052237, -0.03668803],\n",
            "       [ 1.03692688, -0.04420999],\n",
            "       [ 1.05936154, -0.02488539],\n",
            "       [ 1.0534917 ,  0.00646579],\n",
            "       [ 1.02201442,  0.01397187],\n",
            "       [ 1.00195058, -0.0099555 ],\n",
            "       [ 1.01075791, -0.03691214],\n",
            "       [ 1.0372521 , -0.04413909],\n",
            "       [ 1.0594906 , -0.02453977],\n",
            "       [ 1.05322373,  0.00674713],\n",
            "       [ 1.0216531 ,  0.01383891],\n",
            "       [ 1.0018903 , -0.01030632],\n",
            "       [ 1.01099447, -0.0371334 ],\n",
            "       [ 1.03757627, -0.04406419],\n",
            "       [ 1.05961558, -0.02419254],\n",
            "       [ 1.05295268,  0.00702478],\n",
            "       [ 1.02129421,  0.01370157],\n",
            "       [ 1.00183504, -0.01065721],\n",
            "       [ 1.01123466, -0.03735189],\n",
            "       [ 1.03790089, -0.04398545],\n",
            "       [ 1.0597377 , -0.02384367],\n",
            "       [ 1.05267799,  0.00729912],\n",
            "       [ 1.02093741,  0.01355959],\n",
            "       [ 1.0017838 , -0.01100807],\n",
            "       [ 1.01147645, -0.03756765],\n",
            "       [ 1.03822455, -0.04390339],\n",
            "       [ 1.05985481, -0.02349308],\n",
            "       [ 1.05239934,  0.00756987],\n",
            "       [ 1.02058165,  0.01341312],\n",
            "       [ 1.0017359 , -0.01135918],\n",
            "       [ 1.01172004, -0.03778073],\n",
            "       [ 1.03854748, -0.04381758],\n",
            "       [ 1.05996844, -0.02314115],\n",
            "       [ 1.05211715,  0.00783726],\n",
            "       [ 1.02022869,  0.01326271],\n",
            "       [ 1.00169299, -0.01170978],\n",
            "       [ 1.01196673, -0.03799086],\n",
            "       [ 1.03887082, -0.04372844],\n",
            "       [ 1.0600783 , -0.02278709],\n",
            "       [ 1.05183182,  0.00810128],\n",
            "       [ 1.01987751,  0.01310754],\n",
            "       [ 1.00165377, -0.01206044]]), <tf.Tensor 'Placeholder_43:0' shape=(?, 1) dtype=float32>: array([[0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551],\n",
            "       [0.20878551]]), <tf.Tensor 'Placeholder_44:0' shape=(?, 1) dtype=float32>: array([[0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769]]), <tf.Tensor 'Placeholder_45:0' shape=(?, 1) dtype=float32>: array([[ 4.8],\n",
            "       [ 4.9],\n",
            "       [ 5. ],\n",
            "       [ 5.1],\n",
            "       [ 5.2],\n",
            "       [ 5.3],\n",
            "       [ 5.4],\n",
            "       [ 5.5],\n",
            "       [ 5.6],\n",
            "       [ 5.7],\n",
            "       [ 5.8],\n",
            "       [ 5.9],\n",
            "       [ 6. ],\n",
            "       [ 6.1],\n",
            "       [ 6.2],\n",
            "       [ 6.3],\n",
            "       [ 6.4],\n",
            "       [ 6.5],\n",
            "       [ 6.6],\n",
            "       [ 6.7],\n",
            "       [ 6.8],\n",
            "       [ 6.9],\n",
            "       [ 7. ],\n",
            "       [ 7.1],\n",
            "       [ 7.2],\n",
            "       [ 7.3],\n",
            "       [ 7.4],\n",
            "       [ 7.5],\n",
            "       [ 7.6],\n",
            "       [ 7.7],\n",
            "       [ 7.8],\n",
            "       [ 7.9],\n",
            "       [ 8. ],\n",
            "       [ 8.1],\n",
            "       [ 8.2],\n",
            "       [ 8.3],\n",
            "       [ 8.4],\n",
            "       [ 8.5],\n",
            "       [ 8.6],\n",
            "       [ 8.7],\n",
            "       [ 8.8],\n",
            "       [ 8.9],\n",
            "       [ 9. ],\n",
            "       [ 9.1],\n",
            "       [ 9.2],\n",
            "       [ 9.3],\n",
            "       [ 9.4],\n",
            "       [ 9.5],\n",
            "       [ 9.6],\n",
            "       [ 9.7],\n",
            "       [ 9.8],\n",
            "       [ 9.9],\n",
            "       [10. ],\n",
            "       [10.1],\n",
            "       [10.2],\n",
            "       [10.3],\n",
            "       [10.4],\n",
            "       [10.5],\n",
            "       [10.6],\n",
            "       [10.7],\n",
            "       [10.8],\n",
            "       [10.9],\n",
            "       [11. ],\n",
            "       [11.1],\n",
            "       [11.2],\n",
            "       [11.3],\n",
            "       [11.4],\n",
            "       [11.5],\n",
            "       [11.6],\n",
            "       [11.7],\n",
            "       [11.8],\n",
            "       [11.9],\n",
            "       [12. ],\n",
            "       [12.1],\n",
            "       [12.2],\n",
            "       [12.3],\n",
            "       [12.4],\n",
            "       [12.5],\n",
            "       [12.6],\n",
            "       [12.7],\n",
            "       [12.8],\n",
            "       [12.9],\n",
            "       [13. ],\n",
            "       [13.1],\n",
            "       [13.2],\n",
            "       [13.3],\n",
            "       [13.4],\n",
            "       [13.5],\n",
            "       [13.6],\n",
            "       [13.7],\n",
            "       [13.8],\n",
            "       [13.9],\n",
            "       [14. ],\n",
            "       [14.1],\n",
            "       [14.2],\n",
            "       [14.3],\n",
            "       [14.4],\n",
            "       [14.5],\n",
            "       [14.6],\n",
            "       [14.7],\n",
            "       [14.8],\n",
            "       [14.9],\n",
            "       [15. ],\n",
            "       [15.1],\n",
            "       [15.2],\n",
            "       [15.3],\n",
            "       [15.4],\n",
            "       [15.5],\n",
            "       [15.6],\n",
            "       [15.7],\n",
            "       [15.8],\n",
            "       [15.9],\n",
            "       [16. ],\n",
            "       [16.1],\n",
            "       [16.2],\n",
            "       [16.3],\n",
            "       [16.4],\n",
            "       [16.5],\n",
            "       [16.6],\n",
            "       [16.7],\n",
            "       [16.8],\n",
            "       [16.9],\n",
            "       [17. ],\n",
            "       [17.1],\n",
            "       [17.2],\n",
            "       [17.3],\n",
            "       [17.4],\n",
            "       [17.5]]), <tf.Tensor 'Placeholder_46:0' shape=(?, 2) dtype=float32>: array([[ 1.02761523,  0.01540928],\n",
            "       [ 1.00333232, -0.00475917],\n",
            "       [ 1.00748592, -0.03328337],\n",
            "       [ 1.03234096, -0.04481899],\n",
            "       [ 1.05715272, -0.02951888],\n",
            "       [ 1.05682196,  0.00218337],\n",
            "       [ 1.02723435,  0.01534674],\n",
            "       [ 1.00321268, -0.00510007],\n",
            "       [ 1.00768657, -0.03354352],\n",
            "       [ 1.03266855, -0.04479951],\n",
            "       [ 1.05733372, -0.02920314],\n",
            "       [ 1.05661016,  0.00250788],\n",
            "       [ 1.02685087,  0.01527862],\n",
            "       [ 1.00309366, -0.00544118],\n",
            "       [ 1.0078873 , -0.03380111],\n",
            "       [ 1.03299537, -0.04477678],\n",
            "       [ 1.05751172, -0.02888451],\n",
            "       [ 1.05639569,  0.00283004],\n",
            "       [ 1.02647189,  0.01520643],\n",
            "       [ 1.00298312, -0.00578314],\n",
            "       [ 1.00809477, -0.03405481],\n",
            "       [ 1.0333259 , -0.04474952],\n",
            "       [ 1.05768849, -0.02856331],\n",
            "       [ 1.05617795,  0.00315019],\n",
            "       [ 1.02609336,  0.01512916],\n",
            "       [ 1.00287478, -0.00612714],\n",
            "       [ 1.00830259, -0.03430758],\n",
            "       [ 1.03365312, -0.04471916],\n",
            "       [ 1.05785812, -0.02824024],\n",
            "       [ 1.05595276,  0.00346612],\n",
            "       [ 1.0257142 ,  0.01504717],\n",
            "       [ 1.00276917, -0.0064715 ],\n",
            "       [ 1.00851215, -0.03455684],\n",
            "       [ 1.03398096, -0.04468488],\n",
            "       [ 1.05802551, -0.02791433],\n",
            "       [ 1.05572566,  0.00378064],\n",
            "       [ 1.02533902,  0.01496073],\n",
            "       [ 1.00267076, -0.00681678],\n",
            "       [ 1.00872738, -0.0348035 ],\n",
            "       [ 1.03431053, -0.04464647],\n",
            "       [ 1.05819031, -0.02758603],\n",
            "       [ 1.05549431,  0.00409161],\n",
            "       [ 1.02496384,  0.01486936],\n",
            "       [ 1.00257411, -0.00716353],\n",
            "       [ 1.0089426 , -0.03504815],\n",
            "       [ 1.03463752, -0.04460507],\n",
            "       [ 1.05834855, -0.02725593],\n",
            "       [ 1.05525671,  0.00439952],\n",
            "       [ 1.02458892,  0.01477322],\n",
            "       [ 1.00248141, -0.00751073],\n",
            "       [ 1.0091607 , -0.03528979],\n",
            "       [ 1.03496552, -0.04455954],\n",
            "       [ 1.05850532, -0.02692339],\n",
            "       [ 1.0550175 ,  0.00470469],\n",
            "       [ 1.02421759,  0.01467304],\n",
            "       [ 1.00239462, -0.00785835],\n",
            "       [ 1.00938304, -0.03552895],\n",
            "       [ 1.03529421, -0.04451031],\n",
            "       [ 1.0586579 , -0.0265884 ],\n",
            "       [ 1.05477291,  0.00500645],\n",
            "       [ 1.02384592,  0.0145672 ],\n",
            "       [ 1.00230977, -0.00820724],\n",
            "       [ 1.00960531, -0.03576613],\n",
            "       [ 1.03562063, -0.04445799],\n",
            "       [ 1.05880538, -0.02625211],\n",
            "       [ 1.05452383,  0.00530499],\n",
            "       [ 1.02347593,  0.01445756],\n",
            "       [ 1.00222952, -0.00855596],\n",
            "       [ 1.00983124, -0.03600025],\n",
            "       [ 1.0359481 , -0.04440125],\n",
            "       [ 1.0589507 , -0.02591306],\n",
            "       [ 1.05427219,  0.00560047],\n",
            "       [ 1.02310868,  0.01434314],\n",
            "       [ 1.00215435, -0.00890521],\n",
            "       [ 1.01005988, -0.03623214],\n",
            "       [ 1.03627521, -0.04434127],\n",
            "       [ 1.05909147, -0.02557227],\n",
            "       [ 1.05401558,  0.00589236],\n",
            "       [ 1.02274145,  0.01422373],\n",
            "       [ 1.00208154, -0.00925516],\n",
            "       [ 1.0102895 , -0.03646155],\n",
            "       [ 1.03660056, -0.04427773],\n",
            "       [ 1.05922779, -0.02522998],\n",
            "       [ 1.05375509,  0.00618079],\n",
            "       [ 1.02237689,  0.01410023],\n",
            "       [ 1.00201387, -0.00960508],\n",
            "       [ 1.01052237, -0.03668803],\n",
            "       [ 1.03692688, -0.04420999],\n",
            "       [ 1.05936154, -0.02488539],\n",
            "       [ 1.0534917 ,  0.00646579],\n",
            "       [ 1.02201442,  0.01397187],\n",
            "       [ 1.00195058, -0.0099555 ],\n",
            "       [ 1.01075791, -0.03691214],\n",
            "       [ 1.0372521 , -0.04413909],\n",
            "       [ 1.0594906 , -0.02453977],\n",
            "       [ 1.05322373,  0.00674713],\n",
            "       [ 1.0216531 ,  0.01383891],\n",
            "       [ 1.0018903 , -0.01030632],\n",
            "       [ 1.01099447, -0.0371334 ],\n",
            "       [ 1.03757627, -0.04406419],\n",
            "       [ 1.05961558, -0.02419254],\n",
            "       [ 1.05295268,  0.00702478],\n",
            "       [ 1.02129421,  0.01370157],\n",
            "       [ 1.00183504, -0.01065721],\n",
            "       [ 1.01123466, -0.03735189],\n",
            "       [ 1.03790089, -0.04398545],\n",
            "       [ 1.0597377 , -0.02384367],\n",
            "       [ 1.05267799,  0.00729912],\n",
            "       [ 1.02093741,  0.01355959],\n",
            "       [ 1.0017838 , -0.01100807],\n",
            "       [ 1.01147645, -0.03756765],\n",
            "       [ 1.03822455, -0.04390339],\n",
            "       [ 1.05985481, -0.02349308],\n",
            "       [ 1.05239934,  0.00756987],\n",
            "       [ 1.02058165,  0.01341312],\n",
            "       [ 1.0017359 , -0.01135918],\n",
            "       [ 1.01172004, -0.03778073],\n",
            "       [ 1.03854748, -0.04381758],\n",
            "       [ 1.05996844, -0.02314115],\n",
            "       [ 1.05211715,  0.00783726],\n",
            "       [ 1.02022869,  0.01326271],\n",
            "       [ 1.00169299, -0.01170978],\n",
            "       [ 1.01196673, -0.03799086],\n",
            "       [ 1.03887082, -0.04372844],\n",
            "       [ 1.0600783 , -0.02278709],\n",
            "       [ 1.05183182,  0.00810128],\n",
            "       [ 1.01987751,  0.01310754],\n",
            "       [ 1.00165377, -0.01206044]]), <tf.Tensor 'Placeholder_47:0' shape=(?, 1) dtype=float32>: array([[0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953],\n",
            "       [0.78751953]]), <tf.Tensor 'Placeholder_48:0' shape=(?, 1) dtype=float32>: array([[0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769],\n",
            "       [0.07577769]]), <tf.Tensor 'Placeholder_49:0' shape=(?, 1) dtype=float32>: array([[ 4.8],\n",
            "       [ 4.9],\n",
            "       [ 5. ],\n",
            "       [ 5.1],\n",
            "       [ 5.2],\n",
            "       [ 5.3],\n",
            "       [ 5.4],\n",
            "       [ 5.5],\n",
            "       [ 5.6],\n",
            "       [ 5.7],\n",
            "       [ 5.8],\n",
            "       [ 5.9],\n",
            "       [ 6. ],\n",
            "       [ 6.1],\n",
            "       [ 6.2],\n",
            "       [ 6.3],\n",
            "       [ 6.4],\n",
            "       [ 6.5],\n",
            "       [ 6.6],\n",
            "       [ 6.7],\n",
            "       [ 6.8],\n",
            "       [ 6.9],\n",
            "       [ 7. ],\n",
            "       [ 7.1],\n",
            "       [ 7.2],\n",
            "       [ 7.3],\n",
            "       [ 7.4],\n",
            "       [ 7.5],\n",
            "       [ 7.6],\n",
            "       [ 7.7],\n",
            "       [ 7.8],\n",
            "       [ 7.9],\n",
            "       [ 8. ],\n",
            "       [ 8.1],\n",
            "       [ 8.2],\n",
            "       [ 8.3],\n",
            "       [ 8.4],\n",
            "       [ 8.5],\n",
            "       [ 8.6],\n",
            "       [ 8.7],\n",
            "       [ 8.8],\n",
            "       [ 8.9],\n",
            "       [ 9. ],\n",
            "       [ 9.1],\n",
            "       [ 9.2],\n",
            "       [ 9.3],\n",
            "       [ 9.4],\n",
            "       [ 9.5],\n",
            "       [ 9.6],\n",
            "       [ 9.7],\n",
            "       [ 9.8],\n",
            "       [ 9.9],\n",
            "       [10. ],\n",
            "       [10.1],\n",
            "       [10.2],\n",
            "       [10.3],\n",
            "       [10.4],\n",
            "       [10.5],\n",
            "       [10.6],\n",
            "       [10.7],\n",
            "       [10.8],\n",
            "       [10.9],\n",
            "       [11. ],\n",
            "       [11.1],\n",
            "       [11.2],\n",
            "       [11.3],\n",
            "       [11.4],\n",
            "       [11.5],\n",
            "       [11.6],\n",
            "       [11.7],\n",
            "       [11.8],\n",
            "       [11.9],\n",
            "       [12. ],\n",
            "       [12.1],\n",
            "       [12.2],\n",
            "       [12.3],\n",
            "       [12.4],\n",
            "       [12.5],\n",
            "       [12.6],\n",
            "       [12.7],\n",
            "       [12.8],\n",
            "       [12.9],\n",
            "       [13. ],\n",
            "       [13.1],\n",
            "       [13.2],\n",
            "       [13.3],\n",
            "       [13.4],\n",
            "       [13.5],\n",
            "       [13.6],\n",
            "       [13.7],\n",
            "       [13.8],\n",
            "       [13.9],\n",
            "       [14. ],\n",
            "       [14.1],\n",
            "       [14.2],\n",
            "       [14.3],\n",
            "       [14.4],\n",
            "       [14.5],\n",
            "       [14.6],\n",
            "       [14.7],\n",
            "       [14.8],\n",
            "       [14.9],\n",
            "       [15. ],\n",
            "       [15.1],\n",
            "       [15.2],\n",
            "       [15.3],\n",
            "       [15.4],\n",
            "       [15.5],\n",
            "       [15.6],\n",
            "       [15.7],\n",
            "       [15.8],\n",
            "       [15.9],\n",
            "       [16. ],\n",
            "       [16.1],\n",
            "       [16.2],\n",
            "       [16.3],\n",
            "       [16.4],\n",
            "       [16.5],\n",
            "       [16.6],\n",
            "       [16.7],\n",
            "       [16.8],\n",
            "       [16.9],\n",
            "       [17. ],\n",
            "       [17.1],\n",
            "       [17.2],\n",
            "       [17.3],\n",
            "       [17.4],\n",
            "       [17.5]]), <tf.Tensor 'Placeholder_50:0' shape=(?, 2) dtype=float32>: array([[ 1.02761523,  0.01540928],\n",
            "       [ 1.00333232, -0.00475917],\n",
            "       [ 1.00748592, -0.03328337],\n",
            "       [ 1.03234096, -0.04481899],\n",
            "       [ 1.05715272, -0.02951888],\n",
            "       [ 1.05682196,  0.00218337],\n",
            "       [ 1.02723435,  0.01534674],\n",
            "       [ 1.00321268, -0.00510007],\n",
            "       [ 1.00768657, -0.03354352],\n",
            "       [ 1.03266855, -0.04479951],\n",
            "       [ 1.05733372, -0.02920314],\n",
            "       [ 1.05661016,  0.00250788],\n",
            "       [ 1.02685087,  0.01527862],\n",
            "       [ 1.00309366, -0.00544118],\n",
            "       [ 1.0078873 , -0.03380111],\n",
            "       [ 1.03299537, -0.04477678],\n",
            "       [ 1.05751172, -0.02888451],\n",
            "       [ 1.05639569,  0.00283004],\n",
            "       [ 1.02647189,  0.01520643],\n",
            "       [ 1.00298312, -0.00578314],\n",
            "       [ 1.00809477, -0.03405481],\n",
            "       [ 1.0333259 , -0.04474952],\n",
            "       [ 1.05768849, -0.02856331],\n",
            "       [ 1.05617795,  0.00315019],\n",
            "       [ 1.02609336,  0.01512916],\n",
            "       [ 1.00287478, -0.00612714],\n",
            "       [ 1.00830259, -0.03430758],\n",
            "       [ 1.03365312, -0.04471916],\n",
            "       [ 1.05785812, -0.02824024],\n",
            "       [ 1.05595276,  0.00346612],\n",
            "       [ 1.0257142 ,  0.01504717],\n",
            "       [ 1.00276917, -0.0064715 ],\n",
            "       [ 1.00851215, -0.03455684],\n",
            "       [ 1.03398096, -0.04468488],\n",
            "       [ 1.05802551, -0.02791433],\n",
            "       [ 1.05572566,  0.00378064],\n",
            "       [ 1.02533902,  0.01496073],\n",
            "       [ 1.00267076, -0.00681678],\n",
            "       [ 1.00872738, -0.0348035 ],\n",
            "       [ 1.03431053, -0.04464647],\n",
            "       [ 1.05819031, -0.02758603],\n",
            "       [ 1.05549431,  0.00409161],\n",
            "       [ 1.02496384,  0.01486936],\n",
            "       [ 1.00257411, -0.00716353],\n",
            "       [ 1.0089426 , -0.03504815],\n",
            "       [ 1.03463752, -0.04460507],\n",
            "       [ 1.05834855, -0.02725593],\n",
            "       [ 1.05525671,  0.00439952],\n",
            "       [ 1.02458892,  0.01477322],\n",
            "       [ 1.00248141, -0.00751073],\n",
            "       [ 1.0091607 , -0.03528979],\n",
            "       [ 1.03496552, -0.04455954],\n",
            "       [ 1.05850532, -0.02692339],\n",
            "       [ 1.0550175 ,  0.00470469],\n",
            "       [ 1.02421759,  0.01467304],\n",
            "       [ 1.00239462, -0.00785835],\n",
            "       [ 1.00938304, -0.03552895],\n",
            "       [ 1.03529421, -0.04451031],\n",
            "       [ 1.0586579 , -0.0265884 ],\n",
            "       [ 1.05477291,  0.00500645],\n",
            "       [ 1.02384592,  0.0145672 ],\n",
            "       [ 1.00230977, -0.00820724],\n",
            "       [ 1.00960531, -0.03576613],\n",
            "       [ 1.03562063, -0.04445799],\n",
            "       [ 1.05880538, -0.02625211],\n",
            "       [ 1.05452383,  0.00530499],\n",
            "       [ 1.02347593,  0.01445756],\n",
            "       [ 1.00222952, -0.00855596],\n",
            "       [ 1.00983124, -0.03600025],\n",
            "       [ 1.0359481 , -0.04440125],\n",
            "       [ 1.0589507 , -0.02591306],\n",
            "       [ 1.05427219,  0.00560047],\n",
            "       [ 1.02310868,  0.01434314],\n",
            "       [ 1.00215435, -0.00890521],\n",
            "       [ 1.01005988, -0.03623214],\n",
            "       [ 1.03627521, -0.04434127],\n",
            "       [ 1.05909147, -0.02557227],\n",
            "       [ 1.05401558,  0.00589236],\n",
            "       [ 1.02274145,  0.01422373],\n",
            "       [ 1.00208154, -0.00925516],\n",
            "       [ 1.0102895 , -0.03646155],\n",
            "       [ 1.03660056, -0.04427773],\n",
            "       [ 1.05922779, -0.02522998],\n",
            "       [ 1.05375509,  0.00618079],\n",
            "       [ 1.02237689,  0.01410023],\n",
            "       [ 1.00201387, -0.00960508],\n",
            "       [ 1.01052237, -0.03668803],\n",
            "       [ 1.03692688, -0.04420999],\n",
            "       [ 1.05936154, -0.02488539],\n",
            "       [ 1.0534917 ,  0.00646579],\n",
            "       [ 1.02201442,  0.01397187],\n",
            "       [ 1.00195058, -0.0099555 ],\n",
            "       [ 1.01075791, -0.03691214],\n",
            "       [ 1.0372521 , -0.04413909],\n",
            "       [ 1.0594906 , -0.02453977],\n",
            "       [ 1.05322373,  0.00674713],\n",
            "       [ 1.0216531 ,  0.01383891],\n",
            "       [ 1.0018903 , -0.01030632],\n",
            "       [ 1.01099447, -0.0371334 ],\n",
            "       [ 1.03757627, -0.04406419],\n",
            "       [ 1.05961558, -0.02419254],\n",
            "       [ 1.05295268,  0.00702478],\n",
            "       [ 1.02129421,  0.01370157],\n",
            "       [ 1.00183504, -0.01065721],\n",
            "       [ 1.01123466, -0.03735189],\n",
            "       [ 1.03790089, -0.04398545],\n",
            "       [ 1.0597377 , -0.02384367],\n",
            "       [ 1.05267799,  0.00729912],\n",
            "       [ 1.02093741,  0.01355959],\n",
            "       [ 1.0017838 , -0.01100807],\n",
            "       [ 1.01147645, -0.03756765],\n",
            "       [ 1.03822455, -0.04390339],\n",
            "       [ 1.05985481, -0.02349308],\n",
            "       [ 1.05239934,  0.00756987],\n",
            "       [ 1.02058165,  0.01341312],\n",
            "       [ 1.0017359 , -0.01135918],\n",
            "       [ 1.01172004, -0.03778073],\n",
            "       [ 1.03854748, -0.04381758],\n",
            "       [ 1.05996844, -0.02314115],\n",
            "       [ 1.05211715,  0.00783726],\n",
            "       [ 1.02022869,  0.01326271],\n",
            "       [ 1.00169299, -0.01170978],\n",
            "       [ 1.01196673, -0.03799086],\n",
            "       [ 1.03887082, -0.04372844],\n",
            "       [ 1.0600783 , -0.02278709],\n",
            "       [ 1.05183182,  0.00810128],\n",
            "       [ 1.01987751,  0.01310754],\n",
            "       [ 1.00165377, -0.01206044]]), <tf.Tensor 'Placeholder_51:0' shape=(?, 1) dtype=float32>: array([[0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181],\n",
            "       [0.54784181]]), <tf.Tensor 'Placeholder_52:0' shape=(?, 1) dtype=float32>: array([[-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005],\n",
            "       [-0.28904005]]), <tf.Tensor 'Placeholder_53:0' shape=(?, 1) dtype=float32>: array([[ 4.8],\n",
            "       [ 4.9],\n",
            "       [ 5. ],\n",
            "       [ 5.1],\n",
            "       [ 5.2],\n",
            "       [ 5.3],\n",
            "       [ 5.4],\n",
            "       [ 5.5],\n",
            "       [ 5.6],\n",
            "       [ 5.7],\n",
            "       [ 5.8],\n",
            "       [ 5.9],\n",
            "       [ 6. ],\n",
            "       [ 6.1],\n",
            "       [ 6.2],\n",
            "       [ 6.3],\n",
            "       [ 6.4],\n",
            "       [ 6.5],\n",
            "       [ 6.6],\n",
            "       [ 6.7],\n",
            "       [ 6.8],\n",
            "       [ 6.9],\n",
            "       [ 7. ],\n",
            "       [ 7.1],\n",
            "       [ 7.2],\n",
            "       [ 7.3],\n",
            "       [ 7.4],\n",
            "       [ 7.5],\n",
            "       [ 7.6],\n",
            "       [ 7.7],\n",
            "       [ 7.8],\n",
            "       [ 7.9],\n",
            "       [ 8. ],\n",
            "       [ 8.1],\n",
            "       [ 8.2],\n",
            "       [ 8.3],\n",
            "       [ 8.4],\n",
            "       [ 8.5],\n",
            "       [ 8.6],\n",
            "       [ 8.7],\n",
            "       [ 8.8],\n",
            "       [ 8.9],\n",
            "       [ 9. ],\n",
            "       [ 9.1],\n",
            "       [ 9.2],\n",
            "       [ 9.3],\n",
            "       [ 9.4],\n",
            "       [ 9.5],\n",
            "       [ 9.6],\n",
            "       [ 9.7],\n",
            "       [ 9.8],\n",
            "       [ 9.9],\n",
            "       [10. ],\n",
            "       [10.1],\n",
            "       [10.2],\n",
            "       [10.3],\n",
            "       [10.4],\n",
            "       [10.5],\n",
            "       [10.6],\n",
            "       [10.7],\n",
            "       [10.8],\n",
            "       [10.9],\n",
            "       [11. ],\n",
            "       [11.1],\n",
            "       [11.2],\n",
            "       [11.3],\n",
            "       [11.4],\n",
            "       [11.5],\n",
            "       [11.6],\n",
            "       [11.7],\n",
            "       [11.8],\n",
            "       [11.9],\n",
            "       [12. ],\n",
            "       [12.1],\n",
            "       [12.2],\n",
            "       [12.3],\n",
            "       [12.4],\n",
            "       [12.5],\n",
            "       [12.6],\n",
            "       [12.7],\n",
            "       [12.8],\n",
            "       [12.9],\n",
            "       [13. ],\n",
            "       [13.1],\n",
            "       [13.2],\n",
            "       [13.3],\n",
            "       [13.4],\n",
            "       [13.5],\n",
            "       [13.6],\n",
            "       [13.7],\n",
            "       [13.8],\n",
            "       [13.9],\n",
            "       [14. ],\n",
            "       [14.1],\n",
            "       [14.2],\n",
            "       [14.3],\n",
            "       [14.4],\n",
            "       [14.5],\n",
            "       [14.6],\n",
            "       [14.7],\n",
            "       [14.8],\n",
            "       [14.9],\n",
            "       [15. ],\n",
            "       [15.1],\n",
            "       [15.2],\n",
            "       [15.3],\n",
            "       [15.4],\n",
            "       [15.5],\n",
            "       [15.6],\n",
            "       [15.7],\n",
            "       [15.8],\n",
            "       [15.9],\n",
            "       [16. ],\n",
            "       [16.1],\n",
            "       [16.2],\n",
            "       [16.3],\n",
            "       [16.4],\n",
            "       [16.5],\n",
            "       [16.6],\n",
            "       [16.7],\n",
            "       [16.8],\n",
            "       [16.9],\n",
            "       [17. ],\n",
            "       [17.1],\n",
            "       [17.2],\n",
            "       [17.3],\n",
            "       [17.4],\n",
            "       [17.5]]), <tf.Tensor 'Placeholder_54:0' shape=(?, 2) dtype=float32>: array([[ 1.02761523,  0.01540928],\n",
            "       [ 1.00333232, -0.00475917],\n",
            "       [ 1.00748592, -0.03328337],\n",
            "       [ 1.03234096, -0.04481899],\n",
            "       [ 1.05715272, -0.02951888],\n",
            "       [ 1.05682196,  0.00218337],\n",
            "       [ 1.02723435,  0.01534674],\n",
            "       [ 1.00321268, -0.00510007],\n",
            "       [ 1.00768657, -0.03354352],\n",
            "       [ 1.03266855, -0.04479951],\n",
            "       [ 1.05733372, -0.02920314],\n",
            "       [ 1.05661016,  0.00250788],\n",
            "       [ 1.02685087,  0.01527862],\n",
            "       [ 1.00309366, -0.00544118],\n",
            "       [ 1.0078873 , -0.03380111],\n",
            "       [ 1.03299537, -0.04477678],\n",
            "       [ 1.05751172, -0.02888451],\n",
            "       [ 1.05639569,  0.00283004],\n",
            "       [ 1.02647189,  0.01520643],\n",
            "       [ 1.00298312, -0.00578314],\n",
            "       [ 1.00809477, -0.03405481],\n",
            "       [ 1.0333259 , -0.04474952],\n",
            "       [ 1.05768849, -0.02856331],\n",
            "       [ 1.05617795,  0.00315019],\n",
            "       [ 1.02609336,  0.01512916],\n",
            "       [ 1.00287478, -0.00612714],\n",
            "       [ 1.00830259, -0.03430758],\n",
            "       [ 1.03365312, -0.04471916],\n",
            "       [ 1.05785812, -0.02824024],\n",
            "       [ 1.05595276,  0.00346612],\n",
            "       [ 1.0257142 ,  0.01504717],\n",
            "       [ 1.00276917, -0.0064715 ],\n",
            "       [ 1.00851215, -0.03455684],\n",
            "       [ 1.03398096, -0.04468488],\n",
            "       [ 1.05802551, -0.02791433],\n",
            "       [ 1.05572566,  0.00378064],\n",
            "       [ 1.02533902,  0.01496073],\n",
            "       [ 1.00267076, -0.00681678],\n",
            "       [ 1.00872738, -0.0348035 ],\n",
            "       [ 1.03431053, -0.04464647],\n",
            "       [ 1.05819031, -0.02758603],\n",
            "       [ 1.05549431,  0.00409161],\n",
            "       [ 1.02496384,  0.01486936],\n",
            "       [ 1.00257411, -0.00716353],\n",
            "       [ 1.0089426 , -0.03504815],\n",
            "       [ 1.03463752, -0.04460507],\n",
            "       [ 1.05834855, -0.02725593],\n",
            "       [ 1.05525671,  0.00439952],\n",
            "       [ 1.02458892,  0.01477322],\n",
            "       [ 1.00248141, -0.00751073],\n",
            "       [ 1.0091607 , -0.03528979],\n",
            "       [ 1.03496552, -0.04455954],\n",
            "       [ 1.05850532, -0.02692339],\n",
            "       [ 1.0550175 ,  0.00470469],\n",
            "       [ 1.02421759,  0.01467304],\n",
            "       [ 1.00239462, -0.00785835],\n",
            "       [ 1.00938304, -0.03552895],\n",
            "       [ 1.03529421, -0.04451031],\n",
            "       [ 1.0586579 , -0.0265884 ],\n",
            "       [ 1.05477291,  0.00500645],\n",
            "       [ 1.02384592,  0.0145672 ],\n",
            "       [ 1.00230977, -0.00820724],\n",
            "       [ 1.00960531, -0.03576613],\n",
            "       [ 1.03562063, -0.04445799],\n",
            "       [ 1.05880538, -0.02625211],\n",
            "       [ 1.05452383,  0.00530499],\n",
            "       [ 1.02347593,  0.01445756],\n",
            "       [ 1.00222952, -0.00855596],\n",
            "       [ 1.00983124, -0.03600025],\n",
            "       [ 1.0359481 , -0.04440125],\n",
            "       [ 1.0589507 , -0.02591306],\n",
            "       [ 1.05427219,  0.00560047],\n",
            "       [ 1.02310868,  0.01434314],\n",
            "       [ 1.00215435, -0.00890521],\n",
            "       [ 1.01005988, -0.03623214],\n",
            "       [ 1.03627521, -0.04434127],\n",
            "       [ 1.05909147, -0.02557227],\n",
            "       [ 1.05401558,  0.00589236],\n",
            "       [ 1.02274145,  0.01422373],\n",
            "       [ 1.00208154, -0.00925516],\n",
            "       [ 1.0102895 , -0.03646155],\n",
            "       [ 1.03660056, -0.04427773],\n",
            "       [ 1.05922779, -0.02522998],\n",
            "       [ 1.05375509,  0.00618079],\n",
            "       [ 1.02237689,  0.01410023],\n",
            "       [ 1.00201387, -0.00960508],\n",
            "       [ 1.01052237, -0.03668803],\n",
            "       [ 1.03692688, -0.04420999],\n",
            "       [ 1.05936154, -0.02488539],\n",
            "       [ 1.0534917 ,  0.00646579],\n",
            "       [ 1.02201442,  0.01397187],\n",
            "       [ 1.00195058, -0.0099555 ],\n",
            "       [ 1.01075791, -0.03691214],\n",
            "       [ 1.0372521 , -0.04413909],\n",
            "       [ 1.0594906 , -0.02453977],\n",
            "       [ 1.05322373,  0.00674713],\n",
            "       [ 1.0216531 ,  0.01383891],\n",
            "       [ 1.0018903 , -0.01030632],\n",
            "       [ 1.01099447, -0.0371334 ],\n",
            "       [ 1.03757627, -0.04406419],\n",
            "       [ 1.05961558, -0.02419254],\n",
            "       [ 1.05295268,  0.00702478],\n",
            "       [ 1.02129421,  0.01370157],\n",
            "       [ 1.00183504, -0.01065721],\n",
            "       [ 1.01123466, -0.03735189],\n",
            "       [ 1.03790089, -0.04398545],\n",
            "       [ 1.0597377 , -0.02384367],\n",
            "       [ 1.05267799,  0.00729912],\n",
            "       [ 1.02093741,  0.01355959],\n",
            "       [ 1.0017838 , -0.01100807],\n",
            "       [ 1.01147645, -0.03756765],\n",
            "       [ 1.03822455, -0.04390339],\n",
            "       [ 1.05985481, -0.02349308],\n",
            "       [ 1.05239934,  0.00756987],\n",
            "       [ 1.02058165,  0.01341312],\n",
            "       [ 1.0017359 , -0.01135918],\n",
            "       [ 1.01172004, -0.03778073],\n",
            "       [ 1.03854748, -0.04381758],\n",
            "       [ 1.05996844, -0.02314115],\n",
            "       [ 1.05211715,  0.00783726],\n",
            "       [ 1.02022869,  0.01326271],\n",
            "       [ 1.00169299, -0.01170978],\n",
            "       [ 1.01196673, -0.03799086],\n",
            "       [ 1.03887082, -0.04372844],\n",
            "       [ 1.0600783 , -0.02278709],\n",
            "       [ 1.05183182,  0.00810128],\n",
            "       [ 1.01987751,  0.01310754],\n",
            "       [ 1.00165377, -0.01206044]]), <tf.Tensor 'Placeholder_55:0' shape=(?, 1) dtype=float32>: array([[0.43623592],\n",
            "       [0.76297819],\n",
            "       [0.64289352],\n",
            "       [0.29952928],\n",
            "       [0.33463736],\n",
            "       [0.46576418],\n",
            "       [0.2763976 ],\n",
            "       [0.22228444],\n",
            "       [0.7224417 ],\n",
            "       [0.41710717],\n",
            "       [0.33712455],\n",
            "       [0.42246135],\n",
            "       [0.39559503],\n",
            "       [0.26850799],\n",
            "       [0.51815323],\n",
            "       [0.5813008 ],\n",
            "       [0.672484  ],\n",
            "       [0.71597844],\n",
            "       [0.57163838],\n",
            "       [0.27879667],\n",
            "       [0.48126308],\n",
            "       [0.56183336],\n",
            "       [0.24150763],\n",
            "       [0.66699909],\n",
            "       [0.45749249],\n",
            "       [0.62879267],\n",
            "       [0.73321788],\n",
            "       [0.74770797],\n",
            "       [0.765525  ],\n",
            "       [0.67093893],\n",
            "       [0.6407776 ],\n",
            "       [0.66076357],\n",
            "       [0.72315299],\n",
            "       [0.60773731],\n",
            "       [0.64272187],\n",
            "       [0.51779615],\n",
            "       [0.30274953],\n",
            "       [0.22785426],\n",
            "       [0.42303376],\n",
            "       [0.56328764],\n",
            "       [0.43591949],\n",
            "       [0.78259518],\n",
            "       [0.29428975],\n",
            "       [0.33157335],\n",
            "       [0.59463341],\n",
            "       [0.47604698],\n",
            "       [0.4381665 ],\n",
            "       [0.24635176],\n",
            "       [0.69756365],\n",
            "       [0.23862195],\n",
            "       [0.33549205],\n",
            "       [0.25466958],\n",
            "       [0.65221065],\n",
            "       [0.40127351],\n",
            "       [0.76732606],\n",
            "       [0.50826856],\n",
            "       [0.78616604],\n",
            "       [0.29140499],\n",
            "       [0.23351257],\n",
            "       [0.70634825],\n",
            "       [0.24168227],\n",
            "       [0.46924778],\n",
            "       [0.72581906],\n",
            "       [0.51633107],\n",
            "       [0.52255319],\n",
            "       [0.26118687],\n",
            "       [0.54821329],\n",
            "       [0.2741517 ],\n",
            "       [0.55072041],\n",
            "       [0.25292863],\n",
            "       [0.67178864],\n",
            "       [0.25034102],\n",
            "       [0.74301151],\n",
            "       [0.77776606],\n",
            "       [0.54106651],\n",
            "       [0.25468523],\n",
            "       [0.64514774],\n",
            "       [0.68582337],\n",
            "       [0.62566557],\n",
            "       [0.49966971],\n",
            "       [0.42463299],\n",
            "       [0.68400516],\n",
            "       [0.39145656],\n",
            "       [0.52033257],\n",
            "       [0.60507398],\n",
            "       [0.68504   ],\n",
            "       [0.554169  ],\n",
            "       [0.39394626],\n",
            "       [0.3884002 ],\n",
            "       [0.57055448],\n",
            "       [0.4105783 ],\n",
            "       [0.64528123],\n",
            "       [0.56596782],\n",
            "       [0.42006964],\n",
            "       [0.2697488 ],\n",
            "       [0.54690513],\n",
            "       [0.64983007],\n",
            "       [0.37168798],\n",
            "       [0.56767798],\n",
            "       [0.76211286],\n",
            "       [0.33271739],\n",
            "       [0.47011558],\n",
            "       [0.45869738],\n",
            "       [0.25761391],\n",
            "       [0.59321599],\n",
            "       [0.68159898],\n",
            "       [0.57358474],\n",
            "       [0.37696181],\n",
            "       [0.73906672],\n",
            "       [0.71298892],\n",
            "       [0.57827759],\n",
            "       [0.39802742],\n",
            "       [0.69742742],\n",
            "       [0.6392346 ],\n",
            "       [0.43212135],\n",
            "       [0.287432  ],\n",
            "       [0.7463352 ],\n",
            "       [0.24444974],\n",
            "       [0.52656454],\n",
            "       [0.66319295],\n",
            "       [0.77433782],\n",
            "       [0.45757434],\n",
            "       [0.28617615],\n",
            "       [0.71243318],\n",
            "       [0.25227922],\n",
            "       [0.26268741],\n",
            "       [0.56602099],\n",
            "       [0.36721492]]), <tf.Tensor 'Placeholder_56:0' shape=(?, 1) dtype=float32>: array([[ 0.19026323],\n",
            "       [-0.24513244],\n",
            "       [-0.28202221],\n",
            "       [ 0.32075308],\n",
            "       [ 0.26172297],\n",
            "       [ 0.08855963],\n",
            "       [ 0.2969805 ],\n",
            "       [-0.26305959],\n",
            "       [ 0.13245976],\n",
            "       [ 0.24353331],\n",
            "       [-0.22294806],\n",
            "       [ 0.04441041],\n",
            "       [ 0.06157616],\n",
            "       [-0.09107326],\n",
            "       [ 0.18239216],\n",
            "       [-0.14636791],\n",
            "       [ 0.23886385],\n",
            "       [ 0.28654105],\n",
            "       [ 0.01877701],\n",
            "       [ 0.31052874],\n",
            "       [-0.05486814],\n",
            "       [-0.084955  ],\n",
            "       [-0.10816217],\n",
            "       [-0.18346827],\n",
            "       [-0.07087522],\n",
            "       [ 0.32704081],\n",
            "       [ 0.26521755],\n",
            "       [ 0.10871163],\n",
            "       [-0.11894304],\n",
            "       [-0.20934463],\n",
            "       [ 0.02142072],\n",
            "       [ 0.33080313],\n",
            "       [ 0.1261825 ],\n",
            "       [ 0.20361066],\n",
            "       [ 0.05985755],\n",
            "       [-0.28494921],\n",
            "       [ 0.19677359],\n",
            "       [-0.13204845],\n",
            "       [ 0.16905351],\n",
            "       [-0.21281659],\n",
            "       [ 0.12043338],\n",
            "       [ 0.24902242],\n",
            "       [-0.06336704],\n",
            "       [-0.13065107],\n",
            "       [ 0.24054088],\n",
            "       [-0.03850517],\n",
            "       [-0.12903281],\n",
            "       [ 0.12103737],\n",
            "       [ 0.12439265],\n",
            "       [-0.17689577],\n",
            "       [-0.18343083],\n",
            "       [ 0.28204126],\n",
            "       [ 0.03527465],\n",
            "       [ 0.28696949],\n",
            "       [ 0.12897072],\n",
            "       [-0.27697149],\n",
            "       [-0.00974142],\n",
            "       [ 0.22445764],\n",
            "       [-0.19589663],\n",
            "       [-0.03293216],\n",
            "       [-0.27462541],\n",
            "       [-0.04778042],\n",
            "       [ 0.13170502],\n",
            "       [ 0.06974489],\n",
            "       [ 0.19275807],\n",
            "       [-0.00093502],\n",
            "       [ 0.21381348],\n",
            "       [-0.19354606],\n",
            "       [-0.1081182 ],\n",
            "       [ 0.14095167],\n",
            "       [-0.03235484],\n",
            "       [-0.19906262],\n",
            "       [-0.19114489],\n",
            "       [ 0.19580696],\n",
            "       [ 0.22407279],\n",
            "       [ 0.316492  ],\n",
            "       [-0.2108356 ],\n",
            "       [ 0.28712376],\n",
            "       [-0.27237318],\n",
            "       [ 0.29647116],\n",
            "       [-0.0573868 ],\n",
            "       [-0.06804475],\n",
            "       [ 0.02494813],\n",
            "       [-0.18558067],\n",
            "       [-0.26733151],\n",
            "       [-0.05917053],\n",
            "       [ 0.12802412],\n",
            "       [ 0.12569059],\n",
            "       [-0.17333504],\n",
            "       [-0.24995648],\n",
            "       [ 0.32160444],\n",
            "       [-0.03666151],\n",
            "       [-0.06590101],\n",
            "       [ 0.21434028],\n",
            "       [ 0.13459584],\n",
            "       [ 0.2146845 ],\n",
            "       [-0.26295566],\n",
            "       [ 0.22393441],\n",
            "       [-0.28505395],\n",
            "       [ 0.05298221],\n",
            "       [ 0.31738053],\n",
            "       [ 0.12039282],\n",
            "       [ 0.18264013],\n",
            "       [ 0.1786385 ],\n",
            "       [ 0.17180961],\n",
            "       [ 0.07489343],\n",
            "       [-0.22995919],\n",
            "       [ 0.21795869],\n",
            "       [-0.18405447],\n",
            "       [-0.21546588],\n",
            "       [ 0.30401343],\n",
            "       [ 0.1445209 ],\n",
            "       [ 0.18555052],\n",
            "       [-0.0459988 ],\n",
            "       [ 0.21826356],\n",
            "       [-0.26334033],\n",
            "       [ 0.29114915],\n",
            "       [-0.16187342],\n",
            "       [ 0.21428475],\n",
            "       [ 0.30810501],\n",
            "       [ 0.28561815],\n",
            "       [ 0.15453405],\n",
            "       [-0.26730819],\n",
            "       [ 0.26337562],\n",
            "       [ 0.23671201],\n",
            "       [ 0.04766164],\n",
            "       [ 0.0536174 ],\n",
            "       [-0.10564263]]), <tf.Tensor 'Placeholder_57:0' shape=(?, 1) dtype=float32>: array([[0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5],\n",
            "       [0.5]])}\n"
          ]
        }
      ],
      "source": [
        "print(model.tf_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ludDvDDY3_RM",
        "outputId": "d6f64c4b-121f-461a-8b53-2cf23771490b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1)\n"
          ]
        }
      ],
      "source": [
        "print(model.tf_dict[model.x_ini_tf].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4DIv9ukgmma"
      },
      "outputs": [],
      "source": [
        "def load_testdata(snap):\n",
        "    #path=r\"C:\\Users\\Vamsi\\Downloads\\all_pressures\"\n",
        "    path=r\"C:\\Users\\vamsi_oe20s302\\Downloads\\all_pressures\"\n",
        "\n",
        "    uvel=pd.read_csv(path+r\"/u_vel.csv\")\n",
        "    uvel=uvel.to_numpy()\n",
        "\n",
        "    vvel=pd.read_csv(path+r\"/v_vel.csv\")\n",
        "    vvel=vvel.to_numpy()\n",
        "\n",
        "    press=pd.read_csv(path+r\"/static_press.csv\")\n",
        "    press=press.to_numpy()\n",
        "    \n",
        "    xy=pd.read_csv(path+r\"/xy.csv\")\n",
        "    xy=xy.to_numpy()\n",
        "    \n",
        "    t=pd.read_csv(path+r\"/time.csv\")\n",
        "    t=t.to_numpy()\n",
        "    \n",
        "    N=xy.shape[0]\n",
        "    T=t.shape[0]\n",
        "    \n",
        "    TT = np.tile(t, (1,N)).T # N x T\n",
        "    \n",
        "    x_star = xy[:, 0:1]\n",
        "    y_star = xy[:, 1:2]\n",
        "    t_star = TT[:, snap]\n",
        "    X_star=[x_star,y_star,t_star]\n",
        "    \n",
        "    u_star = uvel[:, snap]\n",
        "    v_star = vvel[:, snap]\n",
        "    p_star = press[:, snap]\n",
        "    Y_star=[u_star,v_star,p_star]\n",
        "    \n",
        "    return X_star,Y_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfzwQmGMgmma",
        "outputId": "9596f510-cd4e-46fa-aa30-5a8b8f173c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error u: 2.442662e-01\n",
            "Error v: 9.946948e-01\n",
            "Error p: 2.476408e+00\n"
          ]
        }
      ],
      "source": [
        "# # Testing the load functionality for errors :\n",
        "# filedr='params_3_laptop_run' # Enter the name of the pickle file\n",
        "# model= pinn(data_idx,data_t0,data_sup_b_train,layers,N_train,batch_size,load=True,file=filedr)\n",
        "\n",
        "\n",
        "# # Prediction\n",
        "X_star,Y_star=load_testdata(np.array([100]))\n",
        "u_pred, v_pred, p_pred = model.predict(X_star[0],X_star[1],X_star[2])\n",
        "\n",
        "# # Error\n",
        "error_u = np.linalg.norm(Y_star[0] - u_pred, 2) / np.linalg.norm(Y_star[0], 2)\n",
        "error_v = np.linalg.norm(Y_star[1] - v_pred, 2) / np.linalg.norm(Y_star[1], 2)\n",
        "error_p = np.linalg.norm(Y_star[2] - p_pred, 2) / np.linalg.norm(Y_star[2], 2)\n",
        "\n",
        "print('Error u: %e' % error_u)\n",
        "print('Error v: %e' % error_v)\n",
        "print('Error p: %e' % error_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG-KdpmEU4sG"
      },
      "source": [
        "# Plotting the Predicted Velocity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5YoNUvR2zgx",
        "outputId": "55c80fd2-202b-4e75-f1d1-26d2fb92face"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x24188278208>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "uplot=np.reshape(u_pred,(100,100))\n",
        "plt.imshow(uplot)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhXv1fvLU-Qd"
      },
      "source": [
        "# Plotting the actual velocity "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_qNtEuq2zg0",
        "outputId": "98d7bf96-c5b4-4ebb-bdd9-95ea09754f83",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x1efe4d15d48>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "upl=np.reshape(Y_star[0],(100,100))\n",
        "plt.imshow(upl)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPx2hRcokTKA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "new_sampling_lhs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}